<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Qingzhou Zhang</title>
    <link>https://zqzneptune.github.io/authors/admin/</link>
      <atom:link href="https://zqzneptune.github.io/authors/admin/index.xml" rel="self" type="application/rss+xml" />
    <description>Qingzhou Zhang</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>©2014-2025 Qingzhou Zhang (CC) BY-NC-SA 4.0. All thoughts and opinions here are my own.</copyright><lastBuildDate>Fri, 29 Oct 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://zqzneptune.github.io/images/icon_huf504e8a2f7c5cf9e43cec507892894a0_49847_512x512_fill_lanczos_center_2.png</url>
      <title>Qingzhou Zhang</title>
      <link>https://zqzneptune.github.io/authors/admin/</link>
    </image>
    
    <item>
      <title>Stitching the Atlas Together: How Tangram Puts Single Cells on the Map</title>
      <link>https://zqzneptune.github.io/post/2021-10-29-tangram/</link>
      <pubDate>Fri, 29 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://zqzneptune.github.io/post/2021-10-29-tangram/</guid>
      <description>&lt;h2 id=&#34;the-30-second-lowdown&#34;&gt;The 30-Second Lowdown&lt;/h2&gt;
&lt;p&gt;For years, we&amp;rsquo;ve faced a frustrating tradeoff in genomics. We could either grind up a tissue to get deep, single-cell transcriptomic data (losing all spatial context), or we could use spatial methods that told us where a few genes were, but missed the full picture. The team behind Tangram has developed a powerful computational method to get the best of both worlds. In short, Tangram takes your high-content scRNA-seq data and intelligently &amp;ldquo;maps&amp;rdquo; each cell onto a spatial coordinate system, effectively creating a complete, spatially-resolved transcriptome at single-cell resolution.&lt;/p&gt;
&lt;h2 id=&#34;bridging-the-gap-from-cell-soup-to-tissue-architecture&#34;&gt;Bridging the Gap: From Cell Soup to Tissue Architecture&lt;/h2&gt;
&lt;p&gt;The fundamental problem here is one of integration. We have incredible tools for generating parts lists of tissues—scRNA-seq tells us we have X% T-cells, Y% cancer cells, and Z% fibroblasts. We also have emerging blueprints—spatial transcriptomics shows us the rough neighborhoods where different cell types live. But the parts list isn&amp;rsquo;t connected to the blueprint. We can&amp;rsquo;t see which specific T-cell subtype is talking to which specific cancer clone in its native environment. This is the gap Tangram aims to close. How do we computationally reassemble the &amp;ldquo;cell soup&amp;rdquo; from single-cell sequencing back into the complex, structured tissue it came from?&lt;/p&gt;
&lt;h2 id=&#34;under-the-hood-solving-the-cellular-jigsaw-puzzle&#34;&gt;Under the Hood: Solving the Cellular Jigsaw Puzzle&lt;/h2&gt;
&lt;p&gt;I love the intuition behind this method. Tangram treats the scRNA-seq profiles as individual &amp;ldquo;puzzle pieces&amp;rdquo; and the spatial data (from methods like MERFISH or Visium) as the &amp;ldquo;puzzle board.&amp;rdquo; The key is that both datasets measure a common set of genes. The algorithm works by testing different arrangements of the single-cell puzzle pieces on the spatial board. The goal is simple: find the arrangement that maximizes the spatial correlation between the gene expression patterns in the original spatial data and the newly placed single-cell data. It&amp;rsquo;s a non-convex optimization problem that results in a probabilistic map, telling us the likelihood of finding each specific cell from our scRNA-seq dataset at every location on the spatial map. It&amp;rsquo;s an elegant way to solve an incredibly complex alignment problem.&lt;/p&gt;
&lt;h2 id=&#34;the-whoa-interesting-moment&#34;&gt;The &amp;ldquo;Whoa, Interesting&amp;rdquo; Moment&lt;/h2&gt;
&lt;p&gt;The finding that really made me lean in was their use of Tangram to map multi-omic data. They took SHARE-seq data, which measures both gene expression (RNA) and chromatin accessibility (ATAC) in the same single cells. Here&amp;rsquo;s the brilliant part: they only used the &lt;em&gt;RNA&lt;/em&gt; data to align the cells onto a MERFISH spatial map. But because the ATAC data is linked to the RNA data for each cell, by placing the cell in space, they &lt;em&gt;also&lt;/em&gt; generated a high-resolution spatial map of chromatin accessibility. This is a huge leap. It means we can use one modality (which we can measure spatially) as a scaffold to spatially project another modality (for which we might not have spatial tools). This turns Tangram from a data integration tool into a powerful inference engine.&lt;/p&gt;
&lt;h2 id=&#34;why-this-lands-on-my-roadmap-for-predictive-modeling&#34;&gt;Why This Lands on My Roadmap for Predictive Modeling&lt;/h2&gt;
&lt;p&gt;This paper is more than just a cool method; it’s a foundational piece for building the predictive digital twins that drive my research program. Here’s how I see it through my core lens:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prediction over Description:&lt;/strong&gt; Tangram is a powerful predictive framework. Given a spatial reference, I can now take scRNA-seq from a new sample—say, a resistant leukemia clone—and predict its spatial organization and cellular neighborhood. This allows me to form testable hypotheses about which microenvironmental niches promote drug resistance before I even run the experiment.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Causality over Correlation:&lt;/strong&gt; While Tangram is correlative by nature, it provides the perfect scaffold to overlay causal data. My lab&amp;rsquo;s key differentiator is using large-scale Perturb-seq to establish causal links between genes and cellular states. I can now take this a step further. I can perturb a gene network in a solid tumor model, generate Perturb-seq data, and use Tangram to map these perturbed cells back onto a real patient tumor slice. This allows me to build an &lt;em&gt;in silico&lt;/em&gt; model of how a specific genetic knockout causally remodels the tumor microenvironment. This is the future.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Application to My Pillars:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Leukemia (1A):&lt;/strong&gt; In T-ALL, the bone marrow niche is critical for chemoresistance. I can map scRNA-seq data from patient-derived xenografts (pre- and post-treatment) onto a healthy spatial atlas of the bone marrow. This will allow me to predict which niche interactions are enriched in resistant cells, pointing directly to new therapeutic targets that disrupt the cancer&amp;rsquo;s supportive environment.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Solid Tumors (1B):&lt;/strong&gt; The application here is immediate and obvious. Building predictive models of immunotherapy response requires understanding the spatial crosstalk between cancer cells and immune cells. Tangram allows me to fuse my Perturb-seq data with spatial atlases of the tumor microenvironment to model how silencing a target gene in a cancer cell alters its proximity to cytotoxic T-cells.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;where-we-go-from-here-from-static-maps-to-dynamic-models&#34;&gt;Where We Go From Here: From Static Maps to Dynamic Models&lt;/h3&gt;
&lt;p&gt;Tangram provides a fantastic framework for mapping static snapshots. The clear next step is to make it dynamic.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;My Next Computational Step:&lt;/strong&gt; I&amp;rsquo;m already architecting what I call &amp;ldquo;Differential Tangram.&amp;rdquo; The idea is to map two different scRNA-seq datasets—for example, from a tumor before and after immunotherapy—onto the &lt;em&gt;exact same&lt;/em&gt; spatial scaffold. The output wouldn&amp;rsquo;t be two separate maps, but a single, integrated &amp;ldquo;remodeling map.&amp;rdquo; This map would explicitly quantify the change in probability of a cell type occupying a given location, allowing us to visualize and quantify how a tissue reorganizes in response to therapy. This moves from representation to modeling dynamic biological processes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Key Experiment for the Field:&lt;/strong&gt; The field needs a gold-standard benchmark dataset for validation. The ideal, albeit challenging, experiment would be to perform CRISPR-based perturbation screening (like Perturb-seq) and a high-plex spatial technology (like Xenium or MERFISH) &lt;em&gt;on the same tissue section&lt;/em&gt;. This would create a ground-truth dataset where we know precisely how known genetic perturbations spatially reorganize cells, providing the ultimate test for Tangram and other mapping algorithms.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;a-healthy-dose-of-skepticism&#34;&gt;A Healthy Dose of Skepticism&lt;/h3&gt;
&lt;p&gt;As powerful as Tangram is, it&amp;rsquo;s important to recognize its limitations. First, the model is only as good as its inputs. If your scRNA-seq dataset is missing a cell type that&amp;rsquo;s present in the spatial data (or vice versa), the mapping will be incomplete or forced. This is a critical consideration when trying to map diseased tissue, with its unique cell states, onto a healthy reference atlas. Second, the method relies on assumptions about cell discreteness, which can get complicated in tissues with complex morphology. Finally, by mapping to a reference, there&amp;rsquo;s always a risk of &amp;ldquo;over-normalizing&amp;rdquo; the data—forcing a unique, disease-specific spatial architecture to conform to a pre-existing blueprint, thereby missing novel biology. It&amp;rsquo;s a tool for generating powerful hypotheses, but those hypotheses must always be validated experimentally.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Reference: &lt;a href=&#34;https://www.nature.com/articles/s41592-021-01264-7&#34;&gt;Deep learning and alignment of spatially resolved single-cell transcriptomes with Tangram&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CROP-seq: Linking CRISPR&#39;s &#39;Cut&#39; to the Transcriptome&#39;s &#39;Consequence&#39;</title>
      <link>https://zqzneptune.github.io/post/2021-02-04_cropseqinit/</link>
      <pubDate>Thu, 04 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://zqzneptune.github.io/post/2021-02-04_cropseqinit/</guid>
      <description>&lt;h2 id=&#34;the-bottom-line-up-front&#34;&gt;The Bottom Line Up Front&lt;/h2&gt;
&lt;p&gt;In this foundational 2017 Nature Methods paper, Datlinger and colleagues introduce CROP-seq (CRISPR Droplet Sequencing), a technology that elegantly solves a major bottleneck in functional genomics. They engineered a lentiviral vector to make guide RNAs (gRNAs) directly detectable in droplet-based single-cell RNA-sequencing workflows. This masterstroke created a scalable method to link a specific genetic knockout to its complete, cell-wide transcriptional response, all within a single, pooled experiment.&lt;/p&gt;
&lt;h2 id=&#34;bridging-the-chasm-between-what-if-and-what-is&#34;&gt;Bridging the Chasm Between &amp;lsquo;What If&amp;rsquo; and &amp;lsquo;What Is&amp;rsquo;&lt;/h2&gt;
&lt;p&gt;Before methods like CROP-seq, the world of CRISPR screening was fundamentally divided. On one side, you had pooled screens. These were fantastic for scale—you could test thousands of gene knockouts in one flask—but the readouts were crude. You could measure which perturbations made cells live or die, or maybe turn a single reporter gene on or off. You knew &lt;em&gt;that&lt;/em&gt; a gene was important, but the rich biology of &lt;em&gt;why&lt;/em&gt; remained a black box.&lt;/p&gt;
&lt;p&gt;On the other side were arrayed screens. Here, each perturbation was done in its own well, allowing for deep, high-content readouts like whole-transcriptome sequencing. This gave you the &amp;lsquo;why&amp;rsquo;, but at a tremendous cost in time, labor, and resources. The scale was pitiful. The central challenge was clear: how do you get the best of both worlds? How can we perform thousands of &amp;ldquo;what if&amp;rdquo; experiments (the perturbations) and simultaneously measure &amp;ldquo;what is&amp;rdquo; (the deep, transcriptomic state) for every single one?&lt;/p&gt;
&lt;h2 id=&#34;the-vector-is-the-message&#34;&gt;The Vector is the Message&lt;/h2&gt;
&lt;p&gt;The genius of CROP-seq lies in a clever piece of molecular engineering that enables a massive computational payoff. Standard gRNAs are transcribed by RNA Polymerase III and lack the poly-A tail necessary for capture in most scRNA-seq protocols. The authors re-engineered the lentiviral vector, placing the entire gRNA expression cassette inside the 3&amp;rsquo; Long Terminal Repeat (LTR). During viral integration, this LTR is duplicated, resulting in a gRNA that is not only transcribed by Pol III to guide Cas9, but is &lt;em&gt;also&lt;/em&gt; embedded within a polyadenylated Pol II transcript.&lt;/p&gt;
&lt;p&gt;This is the key that unlocks the entire method. Now, when a single cell is encapsulated in a droplet with an oligo-dT-barcoded bead, the bead captures both the cell’s mRNA and the transcript containing the gRNA. The computational task then becomes beautifully direct: after sequencing, we can map the reads from each cell&amp;rsquo;s barcode, identify the specific gRNA sequence present, and confidently assign that cell’s entire transcriptome to a single, known perturbation. This transforms a messy pool of millions of cells into thousands of discrete, interpretable perturbation experiments.&lt;/p&gt;
&lt;h2 id=&#34;the-self-calibrating-screen&#34;&gt;The Self-Calibrating Screen&lt;/h2&gt;
&lt;p&gt;What really makes this approach powerful is how the rich readout redefines the experiment itself. The proof-of-concept screen of T-cell receptor (TCR) activation is a perfect example. Instead of just asking whether a knockout blocked activation in a binary sense, they used the transcriptomes of the non-targeting control cells to define a continuous &amp;ldquo;TCR activation signature.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;They could then place every single cell, regardless of its perturbation, along this axis. This allowed them to quantify with high resolution exactly &lt;em&gt;how much&lt;/em&gt; a knockout of a key kinase like &lt;code&gt;LCK&lt;/code&gt; blunted the response compared to a knockout of a downstream adaptor. The experiment generates its own internal reference and its own complex, multi-gene phenotypic metric &lt;em&gt;de novo&lt;/em&gt;. It moves us from a simple on/off switch to a high-fidelity biological rheostat.&lt;/p&gt;
&lt;h2 id=&#34;placing-this-work-in-my-universe&#34;&gt;Placing This Work in My Universe&lt;/h2&gt;
&lt;p&gt;This paper isn&amp;rsquo;t just relevant to my research program; it&amp;rsquo;s a cornerstone technology. My goal is to build predictive, causal models of tissue function and dysfunction, and that simply cannot be done with correlational data alone. Technologies like CROP-seq are the engines that produce the causal data I need to build these digital twins.&lt;/p&gt;
&lt;p&gt;For my work in youth leukemia, this is transformative. Instead of just cataloging the genes that are differentially expressed in chemoresistant T-ALL cells, I can use a CROP-seq screen to systematically knock out 500 candidate transcription factors and signaling molecules. By treating the pool with chemotherapy, I can directly identify the perturbations that &lt;em&gt;cause&lt;/em&gt; a cell to adopt a drug-tolerant transcriptional state. This is the direct path to identifying actionable targets to overcome resistance. The same logic applies directly to my interests in the tumor microenvironment and immunotherapy resistance. This method is the bridge between a static cellular atlas and a dynamic, predictive model.&lt;/p&gt;
&lt;h2 id=&#34;the-horizon-my-next-move-and-the-fields-next-challenge&#34;&gt;The Horizon: My Next Move and the Field&amp;rsquo;s Next Challenge&lt;/h2&gt;
&lt;p&gt;This work opened a door to a new type of functional genomics, and the path forward is clear.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;My Next Computational Step:&lt;/strong&gt; The paper largely examines perturbations in steady states. The real frontier is dynamics. My immediate focus is on developing analytical frameworks that integrate CROP-seq data from multiple time points following a perturbation (like drug treatment). The goal is to move beyond simple differential expression and build dynamic gene regulatory network models that infer the &lt;em&gt;trajectory&lt;/em&gt; of cellular response. Can we predict not just the endpoint of drug resistance, but the path a cell takes to get there? This requires marrying causal inference from the knockouts with temporal modeling from the time-series data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Key Experiment for the Field:&lt;/strong&gt; The logical next step is to take these screens in vivo and layer on spatial context. The critical experiment is to deploy a CROP-seq screen in a patient-derived xenograft model of leukemia, then analyze the bone marrow using spatial transcriptomics. This would allow us to link a genetic perturbation within a cancer cell to its cell-intrinsic effects &lt;em&gt;and&lt;/em&gt; its influence on the surrounding microenvironment. Imagine knocking out a secreted factor in a leukemia cell and watching how it reprograms the transcriptional state of nearby stromal and immune cells. That is the future of functional cancer biology.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;a-necessary-word-of-caution&#34;&gt;A Necessary Word of Caution&lt;/h2&gt;
&lt;p&gt;As a pioneering study, it&amp;rsquo;s important to view the work with a critical eye. First, the method&amp;rsquo;s efficiency depends on successfully capturing the gRNA transcript; if that fails, you get a transcriptome without a cause, which is a wasted cell and an expensive problem. Second, the transcriptional effects of single gene knockouts can be subtle, often requiring hundreds of cells per perturbation to achieve statistical power. This poses a challenge to the cost-effectiveness of true genome-wide screens. Finally, CRISPR knockout is a blunt instrument. It tells you the consequence of total gene ablation, but not the more nuanced effects of graded knockdown or disruptions to specific protein functions, which will require the next generation of perturbation tools.&lt;/p&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>From What to Why: How Perturb-seq Rewrote the Rules of Functional Genomics</title>
      <link>https://zqzneptune.github.io/post/2021-02-03_perturbseqinit/</link>
      <pubDate>Wed, 03 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://zqzneptune.github.io/post/2021-02-03_perturbseqinit/</guid>
      <description>&lt;h2 id=&#34;the-core-finding-in-a-nutshell&#34;&gt;The Core Finding in a Nutshell&lt;/h2&gt;
&lt;p&gt;I’m taking a look back at the foundational 2016 paper from the Regev and Friedman labs that introduced Perturb-seq. At its core, they developed a method that welds a pooled CRISPR screen to single-cell RNA sequencing. For the first time, this allowed them to systematically knock out genes and read out the full downstream transcriptional consequences in thousands of individual cells at once, in a single experiment.&lt;/p&gt;
&lt;h2 id=&#34;the-problem-a-chasm-between-scale-and-depth&#34;&gt;The Problem: A Chasm Between Scale and Depth&lt;/h2&gt;
&lt;p&gt;Before this work, functional genomics was a frustrating trade-off. We could either go big with pooled screens that measured simple, one-dimensional outputs like cell survival, or go deep with low-throughput, one-gene-at-a-time transcriptomics. There was simply no way to causally link hundreds of genetic perturbations to high-dimensional phenotypes at scale. How do you build a causal map of a cell&amp;rsquo;s regulatory network if you can only see one intersection at a time? This paper provided the first practical roadmap to bridge that chasm.&lt;/p&gt;
&lt;h2 id=&#34;their-analytical-engine-a-linear-model-with-biological-awareness&#34;&gt;Their Analytical Engine: A Linear Model with Biological Awareness&lt;/h2&gt;
&lt;p&gt;The elegance of Perturb-seq isn&amp;rsquo;t just in the wet lab design. Computationally, they built a framework called MIMOSCA (Multi-Input-Multi-Output-Single-Cell-Analysis). At its heart, it&amp;rsquo;s a regularized linear model that attributes changes in each gene&amp;rsquo;s expression to the presence of a specific sgRNA. The real genius, however, is how they layered in covariates. The model doesn&amp;rsquo;t just capture the perturbation&amp;rsquo;s effect; it systematically models and subtracts the confounding effects of technical noise (like sequencing depth per cell) and, most importantly, pre-existing biological heterogeneity (like cell cycle or differentiation state). This layered approach allows them to isolate the true, direct impact of the gene knockout from other sources of variation.&lt;/p&gt;
&lt;h2 id=&#34;the-result-that-demands-attention&#34;&gt;The Result That Demands Attention&lt;/h2&gt;
&lt;p&gt;The most profound insight for me was their ability to disentangle direct transcriptional regulation from shifts in cell state proportions. When they first modeled the data from dendritic cells, the inferred regulatory network was a bit blurry (Fig 3A). The &amp;lsquo;aha!&amp;rsquo; moment came after they accounted for cell state. They realized that a transcription factor knockout might not create an entirely &lt;em&gt;new&lt;/em&gt; cellular program, but rather push cells from, say, a &amp;ldquo;pro-inflammatory&amp;rdquo; state to an &amp;ldquo;antiviral&amp;rdquo; state—both of which already exist in the unperturbed population. After computationally correcting for this cell state shifting, the direct regulatory links became razor-sharp (Fig 3E). This is a fundamental lesson: a perturbation&amp;rsquo;s effect isn&amp;rsquo;t always to create something novel, but often to change the balance of what&amp;rsquo;s already there. This is a critical concept for understanding drug resistance, where a therapy might simply select for a pre-existing resistant subclone rather than inducing a new program from scratch.&lt;/p&gt;
&lt;h2 id=&#34;how-this-informs-my-predictive-modeling-roadmap&#34;&gt;How This Informs My Predictive Modeling Roadmap&lt;/h2&gt;
&lt;p&gt;This paper is not just another publication; it is the technical and philosophical blueprint for my entire research program. My mission is to build causal, predictive models of tissues, and Perturb-seq is the engine that generates the necessary data to make that possible. My focus on youth leukemia chemoresistance and solid tumor immunology hinges on understanding how cancer cells rewire their networks to survive therapy.&lt;/p&gt;
&lt;p&gt;With the Perturb-seq framework, I can move beyond merely correlating gene expression with a resistant phenotype. I can now systematically knock out transcription factors, signaling molecules, or metabolic enzymes in a patient-derived model and directly observe which pathways are causally required for survival. This provides the raw, causal data needed to build a digital twin that doesn&amp;rsquo;t just describe the resistant state, but can &lt;em&gt;predict&lt;/em&gt; which nodes to target to reverse it. This paper provides the practical embodiment of my &amp;ldquo;Causality over Correlation&amp;rdquo; philosophy.&lt;/p&gt;
&lt;h2 id=&#34;the-horizon-my-next-move-and-the-fields-next-challenge&#34;&gt;The Horizon: My Next Move and the Field&amp;rsquo;s Next Challenge&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;My Next Computational Step:&lt;/strong&gt; The linear model in MIMOSCA was a brilliant and necessary starting point, but biology is rarely linear. My immediate goal is to build on this foundation by developing non-linear models, likely leveraging graph neural networks or variational autoencoders, to capture more complex, synergistic relationships between perturbed genes. The ultimate objective is to build a model that can predict the transcriptional outcome of a &lt;em&gt;combination&lt;/em&gt; of perturbations it has never seen before, moving from inference to true out-of-sample prediction.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Key Experiment for the Field:&lt;/strong&gt; The next frontier is to take this technology from 2D cell culture into more complex, in-vivo like systems. A critical experiment would be to combine Perturb-seq with co-culture organoid models or even direct in-vivo delivery in mouse models of leukemia. Imagine perturbing every known kinase in leukemia cells and then observing how those perturbations causally alter not only the cancer cell&amp;rsquo;s transcriptome but also its communication with the surrounding bone marrow stroma. That is how we will begin to map the networks that drive therapeutic resistance in a truly relevant biological context.&lt;/p&gt;
&lt;h2 id=&#34;a-necessary-word-of-caution&#34;&gt;A Necessary Word of Caution&lt;/h2&gt;
&lt;p&gt;While this work is foundational, it&amp;rsquo;s important to view this 2016 paper through a modern lens. The reliance on gene knockout is a blunt instrument; we now have access to CRISPR interference (CRISPRi) and activation (CRISPRa) for more subtle modulation. The computational model also has to contend with imperfect guide capture and variable knockout efficiency, requiring statistical inference to decide which cells were &amp;ldquo;truly&amp;rdquo; perturbed. This introduces a potential source of modeling noise. Finally, the scale, while groundbreaking for its time, is now more routine. The core challenge they identified—deconvolving combinatorial perturbations—remains the key bottleneck, as the experimental possibility space grows exponentially. Their work laid the foundation, but scaling the analysis to true combinatorial complexity is still the grand challenge for the field.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Reference: &lt;a href=&#34;http://dx.doi.org/10.1016/j.cell.2016.11.038&#34;&gt;Perturb-Seq: Dissecting Molecular Circuits with Scalable Single-Cell RNA Profiling of Pooled Genetic Screens&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Busting the Myth of the scRNA-seq &#34;Dropout&#34;</title>
      <link>https://zqzneptune.github.io/post/2020-01-20-zerodrop/</link>
      <pubDate>Mon, 20 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://zqzneptune.github.io/post/2020-01-20-zerodrop/</guid>
      <description>&lt;h2 id=&#34;the-30-second-lowdown&#34;&gt;The 30-Second Lowdown&lt;/h2&gt;
&lt;p&gt;I love papers that challenge a core assumption we&amp;rsquo;ve all been working with. In this short but powerful correspondence, Valentine Svensson re-examines the widely held belief that droplet-based single-cell RNA-seq data has &amp;ldquo;too many&amp;rdquo; zeros due to technical failures, a phenomenon often called &amp;ldquo;dropout.&amp;rdquo; Using a series of clever analyses on negative control datasets, he demonstrates that the number of observed zeros is almost perfectly explained by standard statistical models of molecule counting. The punchline? The &amp;ldquo;excess&amp;rdquo; zeros we see in our biological data aren&amp;rsquo;t technical noise to be corrected; they are a reflection of real biology.&lt;/p&gt;
&lt;h2 id=&#34;the-ghost-in-the-machine-are-zeros-signal-or-noise&#34;&gt;The Ghost in the Machine: Are Zeros Signal or Noise?&lt;/h2&gt;
&lt;p&gt;A fundamental question in single-cell genomics has always been this: when my data matrix shows a zero for a given gene in a specific cell, what does it mean? Did the technology simply fail to capture an expressed transcript (a &amp;ldquo;technical zero&amp;rdquo;), or is that gene genuinely not being expressed (a &amp;ldquo;biological zero&amp;rdquo;)?&lt;/p&gt;
&lt;p&gt;This isn&amp;rsquo;t just an academic question—it dictates how we build our models. For years, the field has leaned heavily on the idea that technical zeros are rampant, especially in high-throughput droplet methods. This assumption has spawned an entire cottage industry of computational methods for &amp;ldquo;imputation&amp;rdquo;—algorithms designed to predict and fill in these supposed missing values. But if that foundational assumption is shaky, it means we might be spending our time &amp;ldquo;fixing&amp;rdquo; a problem that doesn&amp;rsquo;t exist, and potentially even corrupting the real biological signal in the process.&lt;/p&gt;
&lt;h2 id=&#34;a-clean-experiment-to-settle-the-score&#34;&gt;A Clean Experiment to Settle the Score&lt;/h2&gt;
&lt;p&gt;The beauty of this paper lies not in a complex new algorithm, but in its elegant application of statistical first principles to the right kind of data. Svensson leverages public negative control datasets where, instead of single cells, a uniform solution of RNA is encapsulated into droplets. This creates a perfect testbed: a system with zero biological variation, where any deviation from a simple sampling model must be technical.&lt;/p&gt;
&lt;p&gt;He then fits a standard count model—the negative binomial distribution—to this data. This model is a workhorse for count data and accounts for the fact that capturing molecules is a random process. The result is striking: the model perfectly predicts the observed fraction of zeros without needing any extra &amp;ldquo;zero-inflation&amp;rdquo; component. It’s a textbook case of Occam&amp;rsquo;s razor; the simplest model fits the technical data perfectly.&lt;/p&gt;
&lt;h2 id=&#34;the-finding-that-changes-things&#34;&gt;The Finding That Changes Things&lt;/h2&gt;
&lt;p&gt;The &amp;lsquo;aha!&amp;rsquo; moment for me is the stark visual contrast in Figure 1. When you look at the plots from the technical control experiments (panels a-e), the black dots (observed zero fraction) sit right on top of the gray line (the model&amp;rsquo;s prediction). There is no &amp;ldquo;excess&amp;rdquo; zero problem.&lt;/p&gt;
&lt;p&gt;Then, you look at the plots from real biological samples (panels f-h). Here, you see a clear deviation: many genes have more zeros than predicted by a simple model with a single &amp;ldquo;dispersion&amp;rdquo; parameter for all genes. This is the deviation that has fueled the dropout narrative. But the author shows that once you allow each gene to have its own biological variability (a gene-wise dispersion), the model once again explains the data much better. The takeaway is unambiguous: the platform itself isn&amp;rsquo;t systematically failing. The extra zeros come from biological heterogeneity. Some cells express a gene, others don&amp;rsquo;t. That’s biology, not a bug.&lt;/p&gt;
&lt;h2 id=&#34;why-this-matters-for-building-predictive-models&#34;&gt;Why This Matters for Building Predictive Models&lt;/h2&gt;
&lt;p&gt;This paper lands squarely on my intellectual home turf. My entire research program is geared towards building interpretable, predictive models of living tissues, and that starts with respecting the data. For years, we&amp;rsquo;ve seen increasingly complex imputation models, many of which are black boxes that fundamentally alter the raw counts before any biological questions are asked. This work provides strong evidence that this entire preprocessing step might be a misguided effort.&lt;/p&gt;
&lt;p&gt;If the zeros are real, then trying to &amp;ldquo;fill them in&amp;rdquo; isn&amp;rsquo;t just unnecessary; it&amp;rsquo;s actively destroying information. This gives me much more confidence in using models that work directly with the raw count data, like negative binomial generalized linear models (GLMs). These models are statistically appropriate, more interpretable, and keep us closer to the ground truth of the experiment.&lt;/p&gt;
&lt;p&gt;For my work in leukemia chemoresistance, this is critical. A gene being truly &amp;ldquo;off&amp;rdquo; in a drug-resistant subclone versus &amp;ldquo;on&amp;rdquo; in a sensitive one is a powerful piece of causal evidence. It&amp;rsquo;s a signal I want to model directly, not a technical error to be smoothed over by an imputation algorithm.&lt;/p&gt;
&lt;h2 id=&#34;untapped-potential-and-the-road-ahead&#34;&gt;Untapped Potential and the Road Ahead&lt;/h2&gt;
&lt;p&gt;This work clarifies our thinking, but also points to new directions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;My Next Computational Step:&lt;/strong&gt; The immediate implication is to challenge my own preprocessing pipelines. I plan to systematically benchmark how much imputation actually &lt;em&gt;hurts&lt;/em&gt; the ability to identify the effects of genetic perturbations in my Perturb-seq data. My hypothesis, strengthened by this paper, is that for detecting the strong, often binary on/off gene expression changes induced by CRISPR guides, working directly with the counts will be more powerful and robust than working with imputed data. I&amp;rsquo;ll design this benchmark using my existing T-ALL datasets.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Key Experiment for the Field:&lt;/strong&gt; The author correctly points out that there&amp;rsquo;s a lack of comparable negative control data for plate-based scRNA-seq methods. To truly settle this debate across technologies, the community needs a gold-standard &amp;ldquo;zero-free&amp;rdquo; control experiment for a popular plate-based method like SMART-seq3. This would allow for a definitive, apples-to-apples comparison of the noise profiles and tell us if those platforms &lt;em&gt;do&lt;/em&gt; have unique technical artifacts that might warrant a different statistical approach.&lt;/p&gt;
&lt;h2 id=&#34;a-healthy-dose-of-skepticism&#34;&gt;A Healthy Dose of Skepticism&lt;/h2&gt;
&lt;p&gt;My main critique is that as a &amp;ldquo;correspondence&amp;rdquo; piece, the analysis is necessarily brief. The conclusion—&amp;ldquo;Droplet scRNA-seq is not zero-inflated&amp;rdquo;—is very broad, but the evidence is strongest for UMI-based droplet platforms. The argument against plate-based methods is less direct, relying on re-analysis of a single dataset and another group&amp;rsquo;s simulation study. While the evidence presented for droplet methods is compelling, I&amp;rsquo;d be cautious about over-generalizing this to &lt;em&gt;all&lt;/em&gt; scRNA-seq technologies without more direct, controlled comparisons. The core message is a crucial course correction for the field, but the nuanced differences between technologies still matter.&lt;/p&gt;
&lt;p&gt;Reference: &lt;a href=&#34;https://doi.org/10.1038/s41587-019-0379-5&#34;&gt;&lt;strong&gt;Droplet scRNA-seq is not zero-inflated&lt;/strong&gt;&lt;/a&gt; Nature Biotechnology (2020), by Valentine Svensson&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
