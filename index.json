[{"authors":["admin"],"categories":null,"content":"I am a computational systems biologist dedicated to building predictive models of life. I believe that the next era of biological discovery and therapeutic design will be driven by our ability to learn the causal rules that govern complex cellular systems.\nMy scientific blueprint is to build interpretable AI models from a synthesis of multi-modal data, from single-cell genomics to spatial proteomics. By focusing on perturbation-response experiments, my work moves beyond correlation to infer the causal logic of how cellular networks operate and adapt.\n","date":1635465600,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1635465600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://zqzneptune.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a computational systems biologist dedicated to building predictive models of life. I believe that the next era of biological discovery and therapeutic design will be driven by our ability to learn the causal rules that govern complex cellular systems.\nMy scientific blueprint is to build interpretable AI models from a synthesis of multi-modal data, from single-cell genomics to spatial proteomics. By focusing on perturbation-response experiments, my work moves beyond correlation to infer the causal logic of how cellular networks operate and adapt.","tags":null,"title":"Qingzhou Zhang","type":"authors"},{"authors":["Qingzhou Zhang"],"categories":["Computational Methods"],"content":"The 30-Second Lowdown For years, we\u0026rsquo;ve faced a frustrating tradeoff in genomics. We could either grind up a tissue to get deep, single-cell transcriptomic data (losing all spatial context), or we could use spatial methods that told us where a few genes were, but missed the full picture. The team behind Tangram has developed a powerful computational method to get the best of both worlds. In short, Tangram takes your high-content scRNA-seq data and intelligently \u0026ldquo;maps\u0026rdquo; each cell onto a spatial coordinate system, effectively creating a complete, spatially-resolved transcriptome at single-cell resolution.\nBridging the Gap: From Cell Soup to Tissue Architecture The fundamental problem here is one of integration. We have incredible tools for generating parts lists of tissues—scRNA-seq tells us we have X% T-cells, Y% cancer cells, and Z% fibroblasts. We also have emerging blueprints—spatial transcriptomics shows us the rough neighborhoods where different cell types live. But the parts list isn\u0026rsquo;t connected to the blueprint. We can\u0026rsquo;t see which specific T-cell subtype is talking to which specific cancer clone in its native environment. This is the gap Tangram aims to close. How do we computationally reassemble the \u0026ldquo;cell soup\u0026rdquo; from single-cell sequencing back into the complex, structured tissue it came from?\nUnder the Hood: Solving the Cellular Jigsaw Puzzle I love the intuition behind this method. Tangram treats the scRNA-seq profiles as individual \u0026ldquo;puzzle pieces\u0026rdquo; and the spatial data (from methods like MERFISH or Visium) as the \u0026ldquo;puzzle board.\u0026rdquo; The key is that both datasets measure a common set of genes. The algorithm works by testing different arrangements of the single-cell puzzle pieces on the spatial board. The goal is simple: find the arrangement that maximizes the spatial correlation between the gene expression patterns in the original spatial data and the newly placed single-cell data. It\u0026rsquo;s a non-convex optimization problem that results in a probabilistic map, telling us the likelihood of finding each specific cell from our scRNA-seq dataset at every location on the spatial map. It\u0026rsquo;s an elegant way to solve an incredibly complex alignment problem.\nThe \u0026ldquo;Whoa, Interesting\u0026rdquo; Moment The finding that really made me lean in was their use of Tangram to map multi-omic data. They took SHARE-seq data, which measures both gene expression (RNA) and chromatin accessibility (ATAC) in the same single cells. Here\u0026rsquo;s the brilliant part: they only used the RNA data to align the cells onto a MERFISH spatial map. But because the ATAC data is linked to the RNA data for each cell, by placing the cell in space, they also generated a high-resolution spatial map of chromatin accessibility. This is a huge leap. It means we can use one modality (which we can measure spatially) as a scaffold to spatially project another modality (for which we might not have spatial tools). This turns Tangram from a data integration tool into a powerful inference engine.\nWhy This Lands on My Roadmap for Predictive Modeling This paper is more than just a cool method; it’s a foundational piece for building the predictive digital twins that drive my research program. Here’s how I see it through my core lens:\n  Prediction over Description: Tangram is a powerful predictive framework. Given a spatial reference, I can now take scRNA-seq from a new sample—say, a resistant leukemia clone—and predict its spatial organization and cellular neighborhood. This allows me to form testable hypotheses about which microenvironmental niches promote drug resistance before I even run the experiment.\n  Causality over Correlation: While Tangram is correlative by nature, it provides the perfect scaffold to overlay causal data. My lab\u0026rsquo;s key differentiator is using large-scale Perturb-seq to establish causal links between genes and cellular states. I can now take this a step further. I can perturb a gene network in a solid tumor model, generate Perturb-seq data, and use Tangram to map these perturbed cells back onto a real patient tumor slice. This allows me to build an in silico model of how a specific genetic knockout causally remodels the tumor microenvironment. This is the future.\n  Application to My Pillars:\n  Leukemia (1A): In T-ALL, the bone marrow niche is critical for chemoresistance. I can map scRNA-seq data from patient-derived xenografts (pre- and post-treatment) onto a healthy spatial atlas of the bone marrow. This will allow me to predict which niche interactions are enriched in resistant cells, pointing directly to new therapeutic targets that disrupt the cancer\u0026rsquo;s supportive environment.\n  Solid Tumors (1B): The application here is immediate and obvious. Building predictive models of immunotherapy response requires understanding the spatial crosstalk between cancer cells and immune cells. Tangram allows me to fuse my Perturb-seq data with spatial atlases of the tumor microenvironment to model how silencing a target gene in a cancer cell alters its proximity to cytotoxic T-cells.\n    Where We Go From Here: From Static Maps to Dynamic Models Tangram provides a fantastic framework for mapping static snapshots. The clear next step is to make it dynamic.\n  My Next Computational Step: I\u0026rsquo;m already architecting what I call \u0026ldquo;Differential Tangram.\u0026rdquo; The idea is to map two different scRNA-seq datasets—for example, from a tumor before and after immunotherapy—onto the exact same spatial scaffold. The output wouldn\u0026rsquo;t be two separate maps, but a single, integrated \u0026ldquo;remodeling map.\u0026rdquo; This map would explicitly quantify the change in probability of a cell type occupying a given location, allowing us to visualize and quantify how a tissue reorganizes in response to therapy. This moves from representation to modeling dynamic biological processes.\n  Key Experiment for the Field: The field needs a gold-standard benchmark dataset for validation. The ideal, albeit challenging, experiment would be to perform CRISPR-based perturbation screening (like Perturb-seq) and a high-plex spatial technology (like Xenium or MERFISH) on the same tissue section. This would create a ground-truth dataset where we know precisely how known genetic perturbations spatially reorganize cells, providing the ultimate test for Tangram and other mapping algorithms.\n  A Healthy Dose of Skepticism As powerful as Tangram is, it\u0026rsquo;s important to recognize its limitations. First, the model is only as good as its inputs. If your scRNA-seq dataset is missing a cell type that\u0026rsquo;s present in the spatial data (or vice versa), the mapping will be incomplete or forced. This is a critical consideration when trying to map diseased tissue, with its unique cell states, onto a healthy reference atlas. Second, the method relies on assumptions about cell discreteness, which can get complicated in tissues with complex morphology. Finally, by mapping to a reference, there\u0026rsquo;s always a risk of \u0026ldquo;over-normalizing\u0026rdquo; the data—forcing a unique, disease-specific spatial architecture to conform to a pre-existing blueprint, thereby missing novel biology. It\u0026rsquo;s a tool for generating powerful hypotheses, but those hypotheses must always be validated experimentally.\n Reference: Deep learning and alignment of spatially resolved single-cell transcriptomes with Tangram\n","date":1635465600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635465600,"objectID":"0239bf2806378223340bbabd1228e181","permalink":"https://zqzneptune.github.io/post/2021-10-29-tangram/","publishdate":"2021-10-29T00:00:00Z","relpermalink":"/post/2021-10-29-tangram/","section":"post","summary":"Tangram is a deep learning framework that spatially resolves single-cell RNA-seq data by aligning it to various spatial transcriptomics modalities, creating genome-wide expression maps at single-cell resolution.","tags":["Spatial-Transcriptomics","scRNA-seq","Machine-Learning","Computational-Biology","Data-Integration"],"title":"Stitching the Atlas Together: How Tangram Puts Single Cells on the Map","type":"post"},{"authors":["Qingzhou Zhang"],"categories":["Omics Sequencing"],"content":"The Bottom Line Up Front In this foundational 2017 Nature Methods paper, Datlinger and colleagues introduce CROP-seq (CRISPR Droplet Sequencing), a technology that elegantly solves a major bottleneck in functional genomics. They engineered a lentiviral vector to make guide RNAs (gRNAs) directly detectable in droplet-based single-cell RNA-sequencing workflows. This masterstroke created a scalable method to link a specific genetic knockout to its complete, cell-wide transcriptional response, all within a single, pooled experiment.\nBridging the Chasm Between \u0026lsquo;What If\u0026rsquo; and \u0026lsquo;What Is\u0026rsquo; Before methods like CROP-seq, the world of CRISPR screening was fundamentally divided. On one side, you had pooled screens. These were fantastic for scale—you could test thousands of gene knockouts in one flask—but the readouts were crude. You could measure which perturbations made cells live or die, or maybe turn a single reporter gene on or off. You knew that a gene was important, but the rich biology of why remained a black box.\nOn the other side were arrayed screens. Here, each perturbation was done in its own well, allowing for deep, high-content readouts like whole-transcriptome sequencing. This gave you the \u0026lsquo;why\u0026rsquo;, but at a tremendous cost in time, labor, and resources. The scale was pitiful. The central challenge was clear: how do you get the best of both worlds? How can we perform thousands of \u0026ldquo;what if\u0026rdquo; experiments (the perturbations) and simultaneously measure \u0026ldquo;what is\u0026rdquo; (the deep, transcriptomic state) for every single one?\nThe Vector is the Message The genius of CROP-seq lies in a clever piece of molecular engineering that enables a massive computational payoff. Standard gRNAs are transcribed by RNA Polymerase III and lack the poly-A tail necessary for capture in most scRNA-seq protocols. The authors re-engineered the lentiviral vector, placing the entire gRNA expression cassette inside the 3\u0026rsquo; Long Terminal Repeat (LTR). During viral integration, this LTR is duplicated, resulting in a gRNA that is not only transcribed by Pol III to guide Cas9, but is also embedded within a polyadenylated Pol II transcript.\nThis is the key that unlocks the entire method. Now, when a single cell is encapsulated in a droplet with an oligo-dT-barcoded bead, the bead captures both the cell’s mRNA and the transcript containing the gRNA. The computational task then becomes beautifully direct: after sequencing, we can map the reads from each cell\u0026rsquo;s barcode, identify the specific gRNA sequence present, and confidently assign that cell’s entire transcriptome to a single, known perturbation. This transforms a messy pool of millions of cells into thousands of discrete, interpretable perturbation experiments.\nThe Self-Calibrating Screen What really makes this approach powerful is how the rich readout redefines the experiment itself. The proof-of-concept screen of T-cell receptor (TCR) activation is a perfect example. Instead of just asking whether a knockout blocked activation in a binary sense, they used the transcriptomes of the non-targeting control cells to define a continuous \u0026ldquo;TCR activation signature.\u0026rdquo;\nThey could then place every single cell, regardless of its perturbation, along this axis. This allowed them to quantify with high resolution exactly how much a knockout of a key kinase like LCK blunted the response compared to a knockout of a downstream adaptor. The experiment generates its own internal reference and its own complex, multi-gene phenotypic metric de novo. It moves us from a simple on/off switch to a high-fidelity biological rheostat.\nPlacing This Work in My Universe This paper isn\u0026rsquo;t just relevant to my research program; it\u0026rsquo;s a cornerstone technology. My goal is to build predictive, causal models of tissue function and dysfunction, and that simply cannot be done with correlational data alone. Technologies like CROP-seq are the engines that produce the causal data I need to build these digital twins.\nFor my work in youth leukemia, this is transformative. Instead of just cataloging the genes that are differentially expressed in chemoresistant T-ALL cells, I can use a CROP-seq screen to systematically knock out 500 candidate transcription factors and signaling molecules. By treating the pool with chemotherapy, I can directly identify the perturbations that cause a cell to adopt a drug-tolerant transcriptional state. This is the direct path to identifying actionable targets to overcome resistance. The same logic applies directly to my interests in the tumor microenvironment and immunotherapy resistance. This method is the bridge between a static cellular atlas and a dynamic, predictive model.\nThe Horizon: My Next Move and the Field\u0026rsquo;s Next Challenge This work opened a door to a new type of functional genomics, and the path forward is clear.\n  My Next Computational Step: The paper largely examines perturbations in steady states. The real frontier is dynamics. My immediate focus is on developing analytical frameworks that integrate CROP-seq data from multiple time points following a perturbation (like drug treatment). The goal is to move beyond simple differential expression and build dynamic gene regulatory network models that infer the trajectory of cellular response. Can we predict not just the endpoint of drug resistance, but the path a cell takes to get there? This requires marrying causal inference from the knockouts with temporal modeling from the time-series data.\n  Key Experiment for the Field: The logical next step is to take these screens in vivo and layer on spatial context. The critical experiment is to deploy a CROP-seq screen in a patient-derived xenograft model of leukemia, then analyze the bone marrow using spatial transcriptomics. This would allow us to link a genetic perturbation within a cancer cell to its cell-intrinsic effects and its influence on the surrounding microenvironment. Imagine knocking out a secreted factor in a leukemia cell and watching how it reprograms the transcriptional state of nearby stromal and immune cells. That is the future of functional cancer biology.\n  A Necessary Word of Caution As a pioneering study, it\u0026rsquo;s important to view the work with a critical eye. First, the method\u0026rsquo;s efficiency depends on successfully capturing the gRNA transcript; if that fails, you get a transcriptome without a cause, which is a wasted cell and an expensive problem. Second, the transcriptional effects of single gene knockouts can be subtle, often requiring hundreds of cells per perturbation to achieve statistical power. This poses a challenge to the cost-effectiveness of true genome-wide screens. Finally, CRISPR knockout is a blunt instrument. It tells you the consequence of total gene ablation, but not the more nuanced effects of graded knockdown or disruptions to specific protein functions, which will require the next generation of perturbation tools.\n ","date":1612396800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612396800,"objectID":"a48548e31cfd59e0910c91d52bf64a58","permalink":"https://zqzneptune.github.io/post/2021-02-04_cropseqinit/","publishdate":"2021-02-04T00:00:00Z","relpermalink":"/post/2021-02-04_cropseqinit/","section":"post","summary":"Datlinger et al. introduce CROP-seq, a pioneering method that combines pooled CRISPR screens with single-cell RNA-sequencing to directly link genetic perturbations to their transcriptomic effects.","tags":["CROP-seq","Perturb-seq","Single-Cell","CRISPR","Functional-Genomics"],"title":"CROP-seq: Linking CRISPR's 'Cut' to the Transcriptome's 'Consequence'","type":"post"},{"authors":["Qingzhou Zhang"],"categories":["Omics Sequencing"],"content":"The Core Finding in a Nutshell I’m taking a look back at the foundational 2016 paper from the Regev and Friedman labs that introduced Perturb-seq. At its core, they developed a method that welds a pooled CRISPR screen to single-cell RNA sequencing. For the first time, this allowed them to systematically knock out genes and read out the full downstream transcriptional consequences in thousands of individual cells at once, in a single experiment.\nThe Problem: A Chasm Between Scale and Depth Before this work, functional genomics was a frustrating trade-off. We could either go big with pooled screens that measured simple, one-dimensional outputs like cell survival, or go deep with low-throughput, one-gene-at-a-time transcriptomics. There was simply no way to causally link hundreds of genetic perturbations to high-dimensional phenotypes at scale. How do you build a causal map of a cell\u0026rsquo;s regulatory network if you can only see one intersection at a time? This paper provided the first practical roadmap to bridge that chasm.\nTheir Analytical Engine: A Linear Model with Biological Awareness The elegance of Perturb-seq isn\u0026rsquo;t just in the wet lab design. Computationally, they built a framework called MIMOSCA (Multi-Input-Multi-Output-Single-Cell-Analysis). At its heart, it\u0026rsquo;s a regularized linear model that attributes changes in each gene\u0026rsquo;s expression to the presence of a specific sgRNA. The real genius, however, is how they layered in covariates. The model doesn\u0026rsquo;t just capture the perturbation\u0026rsquo;s effect; it systematically models and subtracts the confounding effects of technical noise (like sequencing depth per cell) and, most importantly, pre-existing biological heterogeneity (like cell cycle or differentiation state). This layered approach allows them to isolate the true, direct impact of the gene knockout from other sources of variation.\nThe Result That Demands Attention The most profound insight for me was their ability to disentangle direct transcriptional regulation from shifts in cell state proportions. When they first modeled the data from dendritic cells, the inferred regulatory network was a bit blurry (Fig 3A). The \u0026lsquo;aha!\u0026rsquo; moment came after they accounted for cell state. They realized that a transcription factor knockout might not create an entirely new cellular program, but rather push cells from, say, a \u0026ldquo;pro-inflammatory\u0026rdquo; state to an \u0026ldquo;antiviral\u0026rdquo; state—both of which already exist in the unperturbed population. After computationally correcting for this cell state shifting, the direct regulatory links became razor-sharp (Fig 3E). This is a fundamental lesson: a perturbation\u0026rsquo;s effect isn\u0026rsquo;t always to create something novel, but often to change the balance of what\u0026rsquo;s already there. This is a critical concept for understanding drug resistance, where a therapy might simply select for a pre-existing resistant subclone rather than inducing a new program from scratch.\nHow This Informs My Predictive Modeling Roadmap This paper is not just another publication; it is the technical and philosophical blueprint for my entire research program. My mission is to build causal, predictive models of tissues, and Perturb-seq is the engine that generates the necessary data to make that possible. My focus on youth leukemia chemoresistance and solid tumor immunology hinges on understanding how cancer cells rewire their networks to survive therapy.\nWith the Perturb-seq framework, I can move beyond merely correlating gene expression with a resistant phenotype. I can now systematically knock out transcription factors, signaling molecules, or metabolic enzymes in a patient-derived model and directly observe which pathways are causally required for survival. This provides the raw, causal data needed to build a digital twin that doesn\u0026rsquo;t just describe the resistant state, but can predict which nodes to target to reverse it. This paper provides the practical embodiment of my \u0026ldquo;Causality over Correlation\u0026rdquo; philosophy.\nThe Horizon: My Next Move and the Field\u0026rsquo;s Next Challenge My Next Computational Step: The linear model in MIMOSCA was a brilliant and necessary starting point, but biology is rarely linear. My immediate goal is to build on this foundation by developing non-linear models, likely leveraging graph neural networks or variational autoencoders, to capture more complex, synergistic relationships between perturbed genes. The ultimate objective is to build a model that can predict the transcriptional outcome of a combination of perturbations it has never seen before, moving from inference to true out-of-sample prediction.\nKey Experiment for the Field: The next frontier is to take this technology from 2D cell culture into more complex, in-vivo like systems. A critical experiment would be to combine Perturb-seq with co-culture organoid models or even direct in-vivo delivery in mouse models of leukemia. Imagine perturbing every known kinase in leukemia cells and then observing how those perturbations causally alter not only the cancer cell\u0026rsquo;s transcriptome but also its communication with the surrounding bone marrow stroma. That is how we will begin to map the networks that drive therapeutic resistance in a truly relevant biological context.\nA Necessary Word of Caution While this work is foundational, it\u0026rsquo;s important to view this 2016 paper through a modern lens. The reliance on gene knockout is a blunt instrument; we now have access to CRISPR interference (CRISPRi) and activation (CRISPRa) for more subtle modulation. The computational model also has to contend with imperfect guide capture and variable knockout efficiency, requiring statistical inference to decide which cells were \u0026ldquo;truly\u0026rdquo; perturbed. This introduces a potential source of modeling noise. Finally, the scale, while groundbreaking for its time, is now more routine. The core challenge they identified—deconvolving combinatorial perturbations—remains the key bottleneck, as the experimental possibility space grows exponentially. Their work laid the foundation, but scaling the analysis to true combinatorial complexity is still the grand challenge for the field.\n Reference: Perturb-Seq: Dissecting Molecular Circuits with Scalable Single-Cell RNA Profiling of Pooled Genetic Screens\n","date":1612310400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612310400,"objectID":"c37b51e5dbf2626110e70edb07cb6e85","permalink":"https://zqzneptune.github.io/post/2021-02-03_perturbseqinit/","publishdate":"2021-02-03T00:00:00Z","relpermalink":"/post/2021-02-03_perturbseqinit/","section":"post","summary":"The seminal Perturb-seq paper established a scalable method to link CRISPR perturbations to their full transcriptomic consequences in single cells, enabling causal network inference.","tags":["Perturb-seq","Functional-Genomics","Causality","scRNA-seq","Computational-Methods"],"title":"From What to Why: How Perturb-seq Rewrote the Rules of Functional Genomics","type":"post"},{"authors":["Qingzhou Zhang"],"categories":["Computational Methods"],"content":"The 30-Second Lowdown I love papers that challenge a core assumption we\u0026rsquo;ve all been working with. In this short but powerful correspondence, Valentine Svensson re-examines the widely held belief that droplet-based single-cell RNA-seq data has \u0026ldquo;too many\u0026rdquo; zeros due to technical failures, a phenomenon often called \u0026ldquo;dropout.\u0026rdquo; Using a series of clever analyses on negative control datasets, he demonstrates that the number of observed zeros is almost perfectly explained by standard statistical models of molecule counting. The punchline? The \u0026ldquo;excess\u0026rdquo; zeros we see in our biological data aren\u0026rsquo;t technical noise to be corrected; they are a reflection of real biology.\nThe Ghost in the Machine: Are Zeros Signal or Noise? A fundamental question in single-cell genomics has always been this: when my data matrix shows a zero for a given gene in a specific cell, what does it mean? Did the technology simply fail to capture an expressed transcript (a \u0026ldquo;technical zero\u0026rdquo;), or is that gene genuinely not being expressed (a \u0026ldquo;biological zero\u0026rdquo;)?\nThis isn\u0026rsquo;t just an academic question—it dictates how we build our models. For years, the field has leaned heavily on the idea that technical zeros are rampant, especially in high-throughput droplet methods. This assumption has spawned an entire cottage industry of computational methods for \u0026ldquo;imputation\u0026rdquo;—algorithms designed to predict and fill in these supposed missing values. But if that foundational assumption is shaky, it means we might be spending our time \u0026ldquo;fixing\u0026rdquo; a problem that doesn\u0026rsquo;t exist, and potentially even corrupting the real biological signal in the process.\nA Clean Experiment to Settle the Score The beauty of this paper lies not in a complex new algorithm, but in its elegant application of statistical first principles to the right kind of data. Svensson leverages public negative control datasets where, instead of single cells, a uniform solution of RNA is encapsulated into droplets. This creates a perfect testbed: a system with zero biological variation, where any deviation from a simple sampling model must be technical.\nHe then fits a standard count model—the negative binomial distribution—to this data. This model is a workhorse for count data and accounts for the fact that capturing molecules is a random process. The result is striking: the model perfectly predicts the observed fraction of zeros without needing any extra \u0026ldquo;zero-inflation\u0026rdquo; component. It’s a textbook case of Occam\u0026rsquo;s razor; the simplest model fits the technical data perfectly.\nThe Finding That Changes Things The \u0026lsquo;aha!\u0026rsquo; moment for me is the stark visual contrast in Figure 1. When you look at the plots from the technical control experiments (panels a-e), the black dots (observed zero fraction) sit right on top of the gray line (the model\u0026rsquo;s prediction). There is no \u0026ldquo;excess\u0026rdquo; zero problem.\nThen, you look at the plots from real biological samples (panels f-h). Here, you see a clear deviation: many genes have more zeros than predicted by a simple model with a single \u0026ldquo;dispersion\u0026rdquo; parameter for all genes. This is the deviation that has fueled the dropout narrative. But the author shows that once you allow each gene to have its own biological variability (a gene-wise dispersion), the model once again explains the data much better. The takeaway is unambiguous: the platform itself isn\u0026rsquo;t systematically failing. The extra zeros come from biological heterogeneity. Some cells express a gene, others don\u0026rsquo;t. That’s biology, not a bug.\nWhy This Matters for Building Predictive Models This paper lands squarely on my intellectual home turf. My entire research program is geared towards building interpretable, predictive models of living tissues, and that starts with respecting the data. For years, we\u0026rsquo;ve seen increasingly complex imputation models, many of which are black boxes that fundamentally alter the raw counts before any biological questions are asked. This work provides strong evidence that this entire preprocessing step might be a misguided effort.\nIf the zeros are real, then trying to \u0026ldquo;fill them in\u0026rdquo; isn\u0026rsquo;t just unnecessary; it\u0026rsquo;s actively destroying information. This gives me much more confidence in using models that work directly with the raw count data, like negative binomial generalized linear models (GLMs). These models are statistically appropriate, more interpretable, and keep us closer to the ground truth of the experiment.\nFor my work in leukemia chemoresistance, this is critical. A gene being truly \u0026ldquo;off\u0026rdquo; in a drug-resistant subclone versus \u0026ldquo;on\u0026rdquo; in a sensitive one is a powerful piece of causal evidence. It\u0026rsquo;s a signal I want to model directly, not a technical error to be smoothed over by an imputation algorithm.\nUntapped Potential and the Road Ahead This work clarifies our thinking, but also points to new directions.\nMy Next Computational Step: The immediate implication is to challenge my own preprocessing pipelines. I plan to systematically benchmark how much imputation actually hurts the ability to identify the effects of genetic perturbations in my Perturb-seq data. My hypothesis, strengthened by this paper, is that for detecting the strong, often binary on/off gene expression changes induced by CRISPR guides, working directly with the counts will be more powerful and robust than working with imputed data. I\u0026rsquo;ll design this benchmark using my existing T-ALL datasets.\nKey Experiment for the Field: The author correctly points out that there\u0026rsquo;s a lack of comparable negative control data for plate-based scRNA-seq methods. To truly settle this debate across technologies, the community needs a gold-standard \u0026ldquo;zero-free\u0026rdquo; control experiment for a popular plate-based method like SMART-seq3. This would allow for a definitive, apples-to-apples comparison of the noise profiles and tell us if those platforms do have unique technical artifacts that might warrant a different statistical approach.\nA Healthy Dose of Skepticism My main critique is that as a \u0026ldquo;correspondence\u0026rdquo; piece, the analysis is necessarily brief. The conclusion—\u0026ldquo;Droplet scRNA-seq is not zero-inflated\u0026rdquo;—is very broad, but the evidence is strongest for UMI-based droplet platforms. The argument against plate-based methods is less direct, relying on re-analysis of a single dataset and another group\u0026rsquo;s simulation study. While the evidence presented for droplet methods is compelling, I\u0026rsquo;d be cautious about over-generalizing this to all scRNA-seq technologies without more direct, controlled comparisons. The core message is a crucial course correction for the field, but the nuanced differences between technologies still matter.\nReference: Droplet scRNA-seq is not zero-inflated Nature Biotechnology (2020), by Valentine Svensson\n","date":1579478400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579478400,"objectID":"7ddf0bb65e177da9b85aceb95b491efa","permalink":"https://zqzneptune.github.io/post/2020-01-20-zerodrop/","publishdate":"2020-01-20T00:00:00Z","relpermalink":"/post/2020-01-20-zerodrop/","section":"post","summary":"This analysis elegantly demonstrates that the high number of zeros in droplet-based scRNA-seq is not a technical artifact but is well-explained by standard count statistics, implying \"excess\" zeros are biological.","tags":["scRNA-seq","Computational-Methods","Statistical-Modeling","Zero-Inflation"],"title":"Busting the Myth of the scRNA-seq \"Dropout\"","type":"post"},{"authors":null,"categories":["Software","Publication"],"content":"The EPIC toolkit was initially published here: Hu, L. Z., et al. \u0026ldquo;EPIC: software toolkit for elution profile-based inference of protein complexes.\u0026rdquo; Nature methods 16.8 (2019): 737-742. Link to the publication\nForked from the orignial repository, I have created RunEPIC to provide the code to run EPIC locally.\n1. Environment The main function in EPIC was implemented in Python, given the headache caused by various libraries, the Anaconda enrionment was used. Simply install Anaconda Python 2.7 version for your convience, and we will start from there.\n2. Prerequisite Let\u0026rsquo;s create the virtual enrionment:\npath to the anaconda directory/bin/conda create -n EPIC python=2.7 anaconda  then we need step up some chanels:\n(EPIC)conda config --add channels defaults (EPIC)conda config --add channels bioconda (EPIC)conda config --add channels conda-forge  get R installed:\n(EPIC)conda install r  start R:\n(EPIC)R  install wccsom for computing WCC scores:\n\u0026gt; install.packages(\u0026quot;kohonen\u0026quot;) \u0026gt; install.packages(\u0026quot;https://cran.r-project.org/src/contrib/Archive/wccsom/wccsom_1.2.11.tar.gz\u0026quot;, type = \u0026quot;source\u0026quot;) \u0026gt; q()  install conda packages:\nconda install requests scikit-learn beautifulsoup4 mock numpy rpy2 python -mpip install -U matplotlib  lastly, make sure Java is installed, so that ClusterOne.jar could be used.\n3. Run EPIC git clone https://github.com/zqzneptune/RunEPIC.git  The main.py in EPIC implemented all the functions:\npython directory to RunEPIC/src/main.py \\ -s 11101001 \\ [Directory to Input Folder/] \\ -c [path to the gold standard file ] \\ [Directory to Output Folder/] \\ -o PrefixName \\ -M RF \\ -n 6 \\ -m COMB \\ -f STRING  ","date":1576195994,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576195994,"objectID":"3eb5b4e7c43222d2c4ba325dcecd7551","permalink":"https://zqzneptune.github.io/post/2019-12-12-runepic/","publishdate":"2019-12-12T18:13:14-06:00","relpermalink":"/post/2019-12-12-runepic/","section":"post","summary":"The EPIC toolkit was initially published here: Hu, L. Z., et al. \u0026ldquo;EPIC: software toolkit for elution profile-based inference of protein complexes.\u0026rdquo; Nature methods 16.8 (2019): 737-742. Link to the publication\nForked from the orignial repository, I have created RunEPIC to provide the code to run EPIC locally.\n1. Environment The main function in EPIC was implemented in Python, given the headache caused by various libraries, the Anaconda enrionment was used.","tags":["Python","Interactome","BF-MS"],"title":"Run EPIC","type":"post"},{"authors":null,"categories":null,"content":"","date":1569024000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569024000,"objectID":"d191d03425e109bcec18ec618f06dd25","permalink":"https://zqzneptune.github.io/publication/j.isci.2019.08.057/","publishdate":"2019-09-04T00:00:00Z","relpermalink":"/publication/j.isci.2019.08.057/","section":"publication","summary":"2019","tags":["Single Cell RNA-seq","Biochemical Fractionation","Mitochondrial","Interactome","Neurogenesis"],"title":"Rewiring of the Human Mitochondrial Interactome during Neuronal Reprogramming Reveals Regulators of the Respirasome and Neurogenesis","type":"publication"},{"authors":null,"categories":null,"content":"","date":1566864000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566864000,"objectID":"19934a68eeaf33edc440413605d0a145","permalink":"https://zqzneptune.github.io/publication/978-981-13-8367-0_6/","publishdate":"2019-08-27T00:00:00Z","relpermalink":"/publication/978-981-13-8367-0_6/","section":"publication","summary":"2018","tags":["Affinity purification","Protein complex","Mass spectrometry","Mitochondrial","Interactome"],"title":"A Tag-Based Affinity Purification Mass Spectrometry Workflow for Systematic Isolation of the Human Mitochondrial Protein Complexes","type":"publication"},{"authors":null,"categories":["Software"],"content":"This R package implements statistical modelling of affinity purification–mass spectrometry (AP-MS) data to compute confidence scores to identify bona fide protein-protein interactions (PPI).\nInstallation The development version can be installed through github:\ndevtools::install_github(repo=\u0026quot;zqzneptune/SMAD\u0026quot;) library(SMAD)  Input Data A demo data.frame was provided as a hint how the input data should strcutured in order to run the scoring functions:\ndata(TestDatInput) colnames(TestDataInput) [1] \u0026quot;idRun\u0026quot; \u0026quot;idBait\u0026quot; \u0026quot;idPrey\u0026quot; \u0026quot;countPrey\u0026quot; \u0026quot;lenPrey\u0026quot;     idRun idBait idPrey countPrey lenPrey     Unique ID of one AP-MS run Bait ID Prey ID Prey peptide count Protein sequence length of the prey    In case of duplcates, a suffix or prefix of e.g. \u0026ldquo;A\u0026rdquo;, \u0026ldquo;B\u0026rdquo; could be added to idRun in order to make \u0026ldquo;idRun-idBait\u0026rdquo; combination unique to each replicate.\nRun scoring 1. CompPASS Comparative Proteomic Analysis Software Suite (CompPASS) is based on spoke model. This algorithm was developed by Dr. Mathew Sowa for defining the human deubiquitinating enzyme interaction landscape (Sowa, Mathew E., et al., 2009). The implementation of this algorithm was inspired by Dr. Sowa\u0026rsquo;s online tutorial. The output includes Z-score, S-score, D-score and WD-score. In its implementation in BioPlex 1.0 (Huttlin, Edward L., et al., 2015) and BioPlex 2.0 (Huttlin, Edward L., et al., 2017), a naive Bayes classifier that learns to distinguish true interacting proteins from non-specific background and false positive identifications was included in the compPASS pipline. This function was optimized from the source code.\nThe input data.frame, datInput, should include:idRun, idBait, idPrey and countPrey.\ndatScore \u0026lt;- CompPASS(datInput)  2. DICE The Dice coefficient is used to score the interaction scores across prey pair-wise combinations, which was proposed by (Bing Zhang et al., 2008)\nThe input data.frame, datInput, should include:idRun and idPrey.\ndatScore \u0026lt;- DICE(datInput)  3. Hart Hart scoring algorithm is based on a hypergeometric distribution error model (Hart et al., 2007).\nThe input data.frame, datInput, should include:idRun and idPrey.\ndatScore \u0026lt;- Hart(datInput)  4. HGScore HGScore algorithm is based on a hypergeometric distribution error model (Hart et al., 2007) with incorporation of NSAF (Zybailov, Boris, et al., 2006). This algorithm was first introduced to predict the protein complex network of Drosophila melanogaster (Guruharsha, K. G., et al., 2011). This scoring algorithm was based on matrix model.\nThe input data.frame, datInput, should include:idRun, idPrey, countPrey and lenPrey.\ndatScore \u0026lt;- HG(datInput)  5. PE PE incorporated both spoke and matrix model as repored in (Sean R. Collins, et al., 2007).\nThe input data.frame, datInput, should include:idRun, idBait and idPrey.\ndatScore \u0026lt;- PE(datInput)  License MIT @ Qingzhou Zhang\n","date":1558537994,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558537994,"objectID":"7288a74d1fd5f425fb7d0f945a123196","permalink":"https://zqzneptune.github.io/post/2019-05-22-smad/","publishdate":"2019-05-22T09:13:14-06:00","relpermalink":"/post/2019-05-22-smad/","section":"post","summary":"This R package implements statistical modelling of affinity purification–mass spectrometry (AP-MS) data to compute confidence scores to identify bona fide protein-protein interactions (PPI).\nInstallation The development version can be installed through github:\ndevtools::install_github(repo=\u0026quot;zqzneptune/SMAD\u0026quot;) library(SMAD)  Input Data A demo data.frame was provided as a hint how the input data should strcutured in order to run the scoring functions:\ndata(TestDatInput) colnames(TestDataInput) [1] \u0026quot;idRun\u0026quot; \u0026quot;idBait\u0026quot; \u0026quot;idPrey\u0026quot; \u0026quot;countPrey\u0026quot; \u0026quot;lenPrey\u0026quot;     idRun idBait idPrey countPrey lenPrey     Unique ID of one AP-MS run Bait ID Prey ID Prey peptide count Protein sequence length of the prey    In case of duplcates, a suffix or prefix of e.","tags":["R","Proteomics","Interactome","AP-MS"],"title":"Statistical Modelling of AP-MS Data (SMAD)","type":"post"},{"authors":null,"categories":["Awsome"],"content":"A collection of resources regarding affinity purification mass spectrometry proteomics for the identification of protein-protein interactions.\nAlgorithms    Year Algorithm Publication Implementation     2006 SAI (socio-affinity index) Anne-Claude Gavin et al., Nature    2007 partial least squares based regression model Rob M Ewing et al., Mol Syst Biol    2007 PE (purification enrichment) Sean R. Collins et al., Molecular \u0026amp; Cellular Proteomics SMAD   2007 Hart G Traver Hart et al., BMC Bioinformatics SMAD   2008 Dice coefficient Bing Zhang et al., Bioinformatics SMAD   2008 PP-NSAF Mihaela E. Sardiu et al., PNAS    2009 CompPASS Mathew E.Sowa et al., Cell SMAD   2010 Decontaminator MathieLavallée-Adam et al. J. Proteome Res.     2011 MiST Stefanie Jäger et al., Nature mist   2011 HGScore K.G.Guruharsha et al., Cell SMAD   2011 SAINT Hyungwon Choi et al., Nature Methods SAINT   2015 SFINX Kevin Titeca et al. J. Proteome Res. SFINX    Datasets    Year Species Abstract Publication     2002 S.cerevisiae 725 bait proteins, one-step immuno-affinity purification based on the Flag epitope tag Yuen Ho et al., Nature   2002 S.cerevisiae tandem-affinity purification processed 1,739 genes Anne-Claude Gavin et al., Nature   2006 S.cerevisiae Genome-wide TAP–MS, first introduced Anne-Claude Gavin et al., Nature   2009 H.sapiens Human Deubiquitinating Enzyme Interaction Landscape(DUB) Mathew E.Sowa et al., Cell   2010 S.cerevisiae kinase and phosphatase interaction (KPI) network Ashton Breitkreutz et al., Science   2009 H.sapiens autophagy interaction network (AIN) Christian Behrends et al., Nature   2011 D.melanogaster a Drosophila protein interaction map (DPiM) K.G.Guruharsha et al., Cell   2012 S.cerevisiae membrane-protein complexes in yeast Mohan Babu et al., Nature   2014 H.sapiens A comprehensive chromatin-related protein-protein interaction map Edyta Marcon et al., Cell Reports   2015 H.sapiens BioPlex v1 Edward L. Huttlin et al., Cell   2015 H.sapiens Autism Spectrum Disorders related Jingjing Li et al., Cell Systems   2016 H.sapiens PPI mapping of 50 unannotated mitochondrial proteins Brendan J.Floyd et al., Molecular Cell   2016 H.sapiens Comprehensive mitochondrial sirtuin interactome Wen Yang et al., Cell   2017 H.sapiens BioPlex v2 Edward L. Huttlin et al., Cell   2017 E.coli Global landscape of cell envelope protein complexes Mohan Babu et al., Nature Biotech   2017 H.sapiens A Map of Human Mitochondrial Protein Interactions related to Neurodegeneration Ramy H.Malty et al., Cell Systems    ","date":1531063394,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531063394,"objectID":"9437dbc4b77c086996be518e755ea4a3","permalink":"https://zqzneptune.github.io/post/2018-07-08-apms/","publishdate":"2018-07-08T09:23:14-06:00","relpermalink":"/post/2018-07-08-apms/","section":"post","summary":"A collection of resources regarding affinity purification mass spectrometry proteomics for the identification of protein-protein interactions.\nAlgorithms    Year Algorithm Publication Implementation     2006 SAI (socio-affinity index) Anne-Claude Gavin et al., Nature    2007 partial least squares based regression model Rob M Ewing et al., Mol Syst Biol    2007 PE (purification enrichment) Sean R. Collins et al., Molecular \u0026amp; Cellular Proteomics SMAD   2007 Hart G Traver Hart et al.","tags":["AP-MS","Interactome"],"title":"Awsome affinity purification mass spectrometry (AP-MS)","type":"post"},{"authors":null,"categories":null,"content":"","date":1511740800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1511740800,"objectID":"b08780d0d7efa313f23283a4f8efba74","permalink":"https://zqzneptune.github.io/publication/nbt.4024/","publishdate":"2017-11-27T00:00:00Z","relpermalink":"/publication/nbt.4024/","section":"publication","summary":"2017","tags":["AP-MS","E.coli","Interactome","Landscape"],"title":"Global landscape of cell envelope protein complexes in Escherichia coli","type":"publication"},{"authors":null,"categories":null,"content":"","date":1510876800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1510876800,"objectID":"fce5f6f4ccb031c1dd5a51a68cafc9c5","permalink":"https://zqzneptune.github.io/publication/j.cels.2017.10.010/","publishdate":"2017-11-08T00:00:00Z","relpermalink":"/publication/j.cels.2017.10.010/","section":"publication","summary":"2017","tags":["AP-MS","Mitochondrial","Interactome","Neurodegeneration"],"title":"A Map of Human Mitochondrial Protein Interactions Linked to Neurodegeneration Reveals New Mechanisms of Redox Homeostasis and NF-κB Signaling","type":"publication"},{"authors":null,"categories":null,"content":"","date":1505952000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505952000,"objectID":"6aa1d9e09ed86cdcf2c7437194c129fc","permalink":"https://zqzneptune.github.io/publication/oncotarget.22413/","publishdate":"2017-09-21T00:00:00Z","relpermalink":"/publication/oncotarget.22413/","section":"publication","summary":"2017","tags":["Whole Exome Sequencing","Mitochondrial","Interactome","Renal Oncocytoma"],"title":"Renal oncocytoma characterized by the defective complex I of the respiratory chain boosts the synthesis of the ROS scavenger glutathione","type":"publication"},{"authors":null,"categories":null,"content":"","date":1412640000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1412640000,"objectID":"c0a8cbb408ad43c03def7c0e376932f7","permalink":"https://zqzneptune.github.io/publication/rged/","publishdate":"2014-09-24T00:00:00Z","relpermalink":"/publication/rged/","section":"publication","summary":"2014","tags":["Database","Gene Expression"],"title":"Renal Gene Expression Database (RGED) a relational database of gene expression profiles in kidney disease","type":"publication"},{"authors":null,"categories":["Database","Publication"],"content":"The Renal Gene Expression Database (RGED) is online. Number of samples colleceted in the database reached around ~10,000, including DNA microarray and RNA-seq experiments.\nJust go ahead to this URL: http://rged.wall-eva.net/\n","date":1406049194,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1406049194,"objectID":"a7313c4b7d36d710550bcf974cf8d75c","permalink":"https://zqzneptune.github.io/post/2014-09-23-rged/","publishdate":"2014-07-23T01:13:14+08:00","relpermalink":"/post/2014-09-23-rged/","section":"post","summary":"The Renal Gene Expression Database (RGED) is online. Number of samples colleceted in the database reached around ~10,000, including DNA microarray and RNA-seq experiments.\nJust go ahead to this URL: http://rged.wall-eva.net/","tags":["Renal Disease","R","Gene Expresssion","PHP"],"title":"Hello, RGED!","type":"post"}]