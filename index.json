[{"authors":["admin"],"categories":null,"content":"I am a computational systems biologist dedicated to building predictive models of life. I believe that the next era of biological discovery and therapeutic design will be driven by our ability to learn the causal rules that govern complex cellular systems.\nMy scientific blueprint is to build interpretable AI models from a synthesis of multi-modal data, from single-cell genomics to spatial proteomics. By focusing on perturbation-response experiments, my work moves beyond correlation to infer the causal logic of how cellular networks operate and adapt.\n","date":1635465600,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1635465600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://zqzneptune.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a computational systems biologist dedicated to building predictive models of life. I believe that the next era of biological discovery and therapeutic design will be driven by our ability to learn the causal rules that govern complex cellular systems.\nMy scientific blueprint is to build interpretable AI models from a synthesis of multi-modal data, from single-cell genomics to spatial proteomics. By focusing on perturbation-response experiments, my work moves beyond correlation to infer the causal logic of how cellular networks operate and adapt.","tags":null,"title":"Qingzhou Zhang","type":"authors"},{"authors":["Qingzhou Zhang"],"categories":["Computational Methods"],"content":"The Bottom Line Up Front I\u0026rsquo;ve just finished reading Biancalani et al.\u0026lsquo;s 2021 Nature Methods paper on \u0026ldquo;Tangram,\u0026rdquo; and it\u0026rsquo;s a piece of work that sits squarely in my wheelhouse. In essence, they\u0026rsquo;ve built a computational tool that solves a fundamental tradeoff in genomics: it takes the deep, genome-wide information from dissociated single-cell sequencing (scRNA-seq) and intelligently projects it back onto a spatial coordinate system derived from technologies like Visium, MERFISH, or even histological images.\nThe \u0026ldquo;Where\u0026rdquo; Problem in Single-Cell Genomics The central challenge this paper tackles is one every computational biologist in this space wrestles with. We live in a world of powerful, but siloed, technologies. On one hand, scRNA-seq gives us an incredibly rich, transcriptome-wide view of individual cells, but to get it, we have to grind up the tissue, destroying all spatial context. We\u0026rsquo;re left with a \u0026lsquo;bag of cells\u0026rsquo;—we know what is there, but not where. On the other hand, spatial technologies like MERFISH or Visium tell us where genes are expressed, but they are either limited to a pre-selected panel of genes or have resolutions coarser than a single cell. The biological puzzle is clear: how do we get the best of both worlds? How do we put the rich molecular puzzle pieces from scRNA-seq back into their original spatial picture?\nUnder the Hood: A Jigsaw Puzzle Solver for Cells Tangram’s approach is elegant. It\u0026rsquo;s a deep learning framework based on non-convex optimization that treats the problem like a massive jigsaw puzzle. The scRNA-seq profiles are the individual puzzle pieces, and the spatial data (e.g., a MERFISH slide) provides the outline or the image on the box. The algorithm computationally \u0026ldquo;places\u0026rdquo; each cell from the scRNA-seq data into a location on the spatial map. The model is trained by rewarding placements that maximize the similarity between the resulting in-silico tissue\u0026rsquo;s gene expression and the real spatial data\u0026rsquo;s gene expression. It iteratively shuffles the cell assignments until the total spatial correlation across all shared genes is maximized. The output is a probabilistic map, telling you the likelihood of finding each specific cell from your single-cell dataset at every voxel of the spatial dataset.\nBeyond Mapping: Imputation as a Superpower Here’s the finding that made me lean in. Tangram is more than just a cell-type mapping tool. Its real power lies in its ability to impute and predict. This is where it aligns perfectly with my mission of building predictive models.\nFirst, they show they can take a targeted MERFISH experiment measuring only ~250 genes and use it as a scaffold to project a full snRNA-seq dataset, effectively creating a genome-wide spatial map with ~27,000 genes at single-cell resolution. This is a massive leap in data generation without running a new experiment.\nSecond, and even more compellingly, they map multi-omic SHARE-seq data (which profiles both RNA and chromatin accessibility in the same cell). By using the RNA modality as the \u0026ldquo;anchor\u0026rdquo; to align to the spatial MERFISH data, they successfully impute the spatial patterns of chromatin accessibility. This is a genuine act of prediction—projecting a data modality into a space where we currently have few tools to measure it directly. This transforms the tool from a descriptive aligner into a predictive engine.\nWeaving Tangram into My Digital Twin Blueprint This work provides a foundational component for the predictive digital twins I aim to build. For my work in youth leukemia, it\u0026rsquo;s a game-changer. I can take a deep scRNA-seq dataset from a bone marrow aspirate—a classic \u0026lsquo;bag of cells\u0026rsquo;—and use Tangram to map those cells back onto a Visium slide from a patient\u0026rsquo;s bone marrow biopsy. This allows me to spatially resolve the locations of chemoresistant clones relative to supportive niches or immune cells. It\u0026rsquo;s the first step to modeling the spatial dependencies that drive drug resistance.\nThe same logic applies directly to my solid tumor pillar. I can build high-resolution maps of the tumor microenvironment, placing specific T-cell exhaustion states or macrophage polarization states in the context of the tumor\u0026rsquo;s architecture. Tangram is the bridge between my perturbation-based causal discovery (from Perturb-seq) and the spatial reality of the tissue. It helps transform a list of cell states and gene programs into a spatially coherent, systems-level model.\nThe Next Frontier: Mapping Causality in Space This paper sets the stage for a critical next step, and it’s where I see my own research program making a unique contribution.\nMy Next Computational Step: The immediate opportunity is to integrate Perturb-seq data with spatial maps. My lab\u0026rsquo;s focus is on using CRISPR screens to build causal models of disease. The logical extension is to run a Perturb-seq screen on cancer cells, then use Tangram to map those perturbed cells back onto a spatial atlas of a tumor. This would allow me to ask questions like: if I knock out Gene X, which is critical for metastasis, where do those cells now localize in the tumor? How does that knockout causally influence the gene expression of its immediate neighbors? This fuses causal inference with spatial biology, moving us toward predictive models of how genetic perturbations rewire entire tissue ecosystems.\nKey Experiment for the Field: The boldest claim in the paper is the imputation of spatial chromatin accessibility. This needs rigorous experimental validation. The key experiment would be to take a tissue block, perform MERFISH on one section, and use a next-generation spatial-ATAC technology on an adjacent serial section. This would create a ground-truth dataset to directly compare against Tangram\u0026rsquo;s imputed ATAC-seq patterns. Passing this test would be a powerful confirmation of the algorithm\u0026rsquo;s predictive capabilities across modalities.\nA Necessary Dose of Skepticism As powerful as this is, it\u0026rsquo;s important to recognize the inherent assumptions. The model\u0026rsquo;s accuracy is fundamentally capped by the quality of its inputs. It assumes the scRNA-seq dataset is a comprehensive representation of the cell populations present in the spatial slice. If a rare but critical cell type is absent from your single-cell prep due to sampling bias or dissociation artifacts—the \u0026lsquo;missing puzzle piece\u0026rsquo; scenario—Tangram has no way to place it. The model can\u0026rsquo;t invent what it hasn\u0026rsquo;t seen. Furthermore, its ability to deconvolve coarse technologies like Visium is powerful, but the placement of individual cells within a single 50-micron spot is a probabilistic estimation, not a direct measurement. We must be careful not to over-interpret the precision at the sub-spot level.\n Reference Biancalani, Tommaso, et al. \u0026ldquo;Deep learning and alignment of spatially resolved single-cell transcriptomes with Tangram.\u0026quot; Nature methods 18.11 (2021): 1352-1362.\n","date":1635465600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635465600,"objectID":"0239bf2806378223340bbabd1228e181","permalink":"https://zqzneptune.github.io/post/2021-10-29-tangram/","publishdate":"2021-10-29T00:00:00Z","relpermalink":"/post/2021-10-29-tangram/","section":"post","summary":"The Tangram algorithm uses deep learning to align dissociated single-cell RNA-seq data onto spatial transcriptomics data, enabling genome-wide spatial mapping and imputation.","tags":["Spatial-Transcriptomics","Computational-Biology","Deep-Learning","Multi-Omics"],"title":"Tangram: Stitching the Cellular Map Back Together","type":"post"},{"authors":["Qingzhou Zhang"],"categories":["Computational Methods"],"content":"The Core Finding in a Nutshell I\u0026rsquo;ve been thinking a lot about the foundational papers that enable my entire research program, and this 2017 classic from Christoph Bock\u0026rsquo;s lab is undoubtedly one of them. Datlinger et al. present CROP-seq, a method that ingeniously combines pooled CRISPR screening with single-cell RNA sequencing. By engineering a lentiviral vector that makes the guide RNA (gRNA) itself detectable in a standard scRNA-seq workflow, they created a one-pot system to knock out thousands of different genes and read out their full transcriptomic consequences in thousands of individual cells.\nBeyond \u0026lsquo;Live or Die\u0026rsquo;: The Quest for Richer Functional Screens For years, functional genomics was caught between two paradigms. On one hand, you had pooled CRISPR screens—incredibly powerful and scalable, but limited to crude, binary readouts like cell survival or the expression of a single fluorescent reporter. They could tell you if a gene was important, but not why. On the other hand, you had arrayed screens, where you\u0026rsquo;d knock out one gene per well. This allowed for rich readouts like RNA-seq, but it was painfully low-throughput and expensive. The central challenge was clear: how do we get the rich, molecular-level data of arrayed screens at the scale of a pooled screen? How do we move beyond simple correlation to build a causal, predictive understanding of gene function?\nThe Elegant Hack: Making gRNAs Visible to the Sequencer The technical barrier was that gRNAs are transcribed by RNA Polymerase III and lack the poly-A tails needed for capture by the oligo-dT primers used in most scRNA-seq protocols. The CROP-seq vector is the solution, and it’s a beautiful piece of molecular engineering. The authors placed the entire gRNA expression cassette within the 3\u0026rsquo; Long Terminal Repeat (LTR) of a lentiviral vector. A quirk of lentiviral replication is that this 3\u0026rsquo; LTR is duplicated to the 5\u0026rsquo; end upon integration into the host genome. The result is that the gRNA sequence becomes part of a polyadenylated RNA Polymerase II transcript, making it perfectly visible to the sequencer alongside the cell\u0026rsquo;s own mRNAs. Critically, the original cassette still expresses a functional gRNA to direct Cas9. This allows the core computational step: in a massive pool of sequenced cells, we can now unambiguously assign a specific genetic perturbation (the gRNA) to a specific phenotypic outcome (the single-cell transcriptome).\nThe Barcode Is the Message For me, the most profound insight of this paper is its design simplicity. While concurrent methods like the initial version of Perturb-seq used a separate transcribed barcode, CROP-seq makes the gRNA sequence itself the identifier. This is not a minor detail. It means the method is fully compatible with standard, widely available pooled gRNA libraries and cloning protocols. By making the perturbing agent its own detectable barcode, they dramatically lowered the barrier to entry and created a system built for massive scale. This is the kind of thinking that truly democratizes a technology and unlocks its full potential.\nA Foundational Tool for My Predictive Modeling Mission This paper, along with the seminal Perturb-seq papers from the Regev and Weissman labs published around the same time, provides the technological bedrock for my entire mission to build predictive models of living tissues. My goal is to move from descriptive snapshots to causal, predictive digital twins. CROP-seq is the engine that produces the exact kind of data I need: high-throughput, high-dimensional measurements of causal relationships between genotype (the knockout) and phenotype (the transcriptome).\nThe authors\u0026rsquo; proof-of-concept screen of T-cell receptor signaling in Jurkat cells—a T-ALL cell line—is a direct signpost for my primary research pillar. I can immediately see the path to applying this exact framework to dissect the gene regulatory networks that drive chemoresistance in youth leukemia. By perturbing genes and observing the resulting transcriptomic shifts in the face of chemotherapy, we can build models that predict which pathways a cancer cell will use to evade treatment. This is the blueprint.\nFrom Pathways to Networks: The Next Computational Frontier This work opens the door, but the journey is just beginning. The analytical approach in the paper largely involves averaging the transcriptomes of all cells that received the same gRNA to create a bulk-like \u0026ldquo;signature.\u0026rdquo; This is powerful, but it discards the rich heterogeneity that is the whole point of single-cell analysis.\nMy Next Computational Step: Instead of calculating an average perturbation effect, my focus is on modeling the full distribution of cellular states that arise from a single knockout. Drug resistance is rarely a uniform phenomenon; it emerges from the tails of a distribution. By modeling how a perturbation reshapes this distribution, we can identify the rare, emergent cell states that lead to treatment failure. This data is the ideal fuel for training the interpretable Gene Regulatory Network (GRN) models that are central to my lab\u0026rsquo;s vision, allowing us to predict perturbation effects in silico.\nKey Experiment for the Field: The next essential move is to take this technology from sterile cell culture plates into more complex, physiologically relevant systems. A pivotal experiment would be to perform a CROP-seq screen in a patient-derived xenograft (PDX) model of B-ALL during chemotherapy treatment. This would allow us to screen for drivers of resistance not in isolation, but within the context of a living tumor microenvironment, revealing the causal gene networks that matter in a patient.\nScrutinizing the Signal: Limitations and Lookouts Of course, no method is without its limitations. The primary challenge with this approach is statistical power. The transcriptomic effect of a single gene knockout can be subtle, especially for genes in redundant pathways. This means a large number of cells must be sequenced for each gRNA to confidently detect a signal, which has cost implications. Furthermore, the capture efficiency of the gRNA transcript isn\u0026rsquo;t perfect, leading to some cells where we get a transcriptome but can\u0026rsquo;t identify the perturbation. Finally, the reliance on lentivirus is a key constraint; it works beautifully in immortalized cell lines but can be challenging to implement in primary cells, particularly non-dividing ones like mature neurons, which is a consideration for my long-term neurodegeneration work. Acknowledging these practical hurdles is the first step in designing the next generation of experiments.\n Reference Datlinger, Paul, et al. \u0026ldquo;Pooled CRISPR screening with single-cell transcriptome readout.\u0026quot; Nature methods 14.3 (2017): 297-301.\n","date":1612396800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612396800,"objectID":"a48548e31cfd59e0910c91d52bf64a58","permalink":"https://zqzneptune.github.io/post/2021-02-04_cropseqinit/","publishdate":"2021-02-04T00:00:00Z","relpermalink":"/post/2021-02-04_cropseqinit/","section":"post","summary":"Datlinger et al. introduce CROP-seq, a method that captures both a CRISPR guide RNA and its resulting single-cell transcriptome, enabling causal gene function mapping at unprecedented scale.","tags":["Perturb-seq","CRISPR-Screen","scRNA-seq","Functional-Genomics","Causal-Inference"],"title":"The Blueprint for Causal Biology: CROP-seq Links Gene to Function at Scale","type":"post"},{"authors":["Qingzhou Zhang"],"categories":["Omics Sequencing"],"content":"The Bottom Line Up Front I\u0026rsquo;ve just revisited the foundational 2016 Cell paper from the Regev and Weissman labs describing Perturb-seq, and its importance has only grown over time. They ingeniously fused pooled CRISPR-based genetic screens with high-throughput single-cell RNA-sequencing. This creates a system where, in a single experiment, you can knock out hundreds of different genes across a population of cells and read out the full transcriptional consequence of each specific perturbation inside each individual cell. It\u0026rsquo;s a landmark in functional genomics.\nBreaking the Screen-or-Profile Dilemma The scientific quest here was to resolve a frustrating tradeoff that defined functional genomics for years. On one side, we had pooled CRISPR screens. These are incredibly scalable—you can test thousands of genes at once—but the readout is typically a single, low-content metric like cell survival or the expression of one fluorescent reporter. You learn that a gene is important, but not why. On the other side, we could perform RNA-seq on cells after knocking out a single gene. This gives an incredibly rich, high-content view of the molecular fallout, but it\u0026rsquo;s painstakingly slow and expensive, done one gene at a time. The central challenge was how to get the best of both: the massive scale of a pooled screen combined with the deep, mechanistic insight of whole-transcriptome profiling.\nThe Barcode is the Rosetta Stone The core of Perturb-seq is an elegant technical and computational solution. The key is a lentiviral vector that delivers not only a specific single-guide RNA (sgRNA) to enact a CRISPR knockout but also a transcribed \u0026ldquo;guide barcode\u0026rdquo; (GBC). When the cells are processed using droplet-based scRNA-seq, this GBC is captured along with all the other mRNAs from that cell. The GBC is the Rosetta Stone: it allows the authors to definitively link a specific genetic perturbation to a specific high-dimensional transcriptomic profile for thousands of cells in parallel.\nComputationally, they then developed a framework (MIMOSCA) to make sense of this massive dataset. Using a regularized linear model, they can deconvolve the specific effect of each perturbation from the complex, pooled data. Crucially, the model is designed to parse out the true perturbation effects from other sources of variation, like the cell cycle, technical noise, or batch effects, which is essential for isolating a clean biological signal.\nFrom Single Genes to a Network Diagram The finding that truly drives home the power of this method isn\u0026rsquo;t just the ability to see which genes go up or down after a knockout. The \u0026lsquo;aha!\u0026rsquo; moment is seeing how they use these rich phenotypes to reconstruct biological circuits. In their demonstration in bone marrow-derived dendritic cells (BMDCs), they perturbed 24 different transcription factors (TFs) involved in the immune response. By clustering the resulting transcriptional signatures, they could group TFs into functional modules—for example, correctly identifying Stat1 and Stat2 as a cooperative module in the anti-viral response. They went beyond a simple list of gene-phenotype links and generated a data-driven wiring diagram of the regulatory network, complete with activating and repressive relationships. This is a monumental step towards interpretability and systems-level understanding.\nThis Isn\u0026rsquo;t Just a Paper; It\u0026rsquo;s My Lab\u0026rsquo;s Foundation I can\u0026rsquo;t overstate this: Perturb-seq is the bedrock of my research philosophy and the engine for my entire lab\u0026rsquo;s mission. My goal is to build predictive, causal models of tissues, and this technology is the single most effective tool for generating the necessary causal data at scale.\nI can use this exact framework to knock out hundreds of candidate genes in T-ALL cell lines, expose them to chemotherapy, and identify the complete transcriptional programs that are causally responsible for driving chemoresistance. I can also screen for genes in cancer cells that causally alter the expression of checkpoint ligands or, in co-culture systems, screen for genes in T-cells that drive the exhaustion phenotype.\nThis method is the physical embodiment of my guiding principles. It moves beyond correlation to causality via direct perturbation. It enables prediction by showing what happens to the entire cellular system if a specific gene is removed. And the high-content transcriptomic readout provides the raw material needed to build interpretable models of the underlying gene regulatory networks.\nScaling Causality: Multi-omics and In Vivo Screens The original Perturb-seq paper was a starting pistol, not a finish line. It immediately opened doors to even more powerful applications, which is where I plan to focus my own computational efforts.\nMy Next Computational Step: The logical evolution is to move from a single RNA readout to a multi-modal one. My immediate focus is on building the analytical frameworks to handle Perturb-Multiome, where we simultaneously profile the transcriptome and the epigenome (via scATAC-seq) from each perturbed cell. This allows us to ask deeper causal questions: how does knocking out a transcription factor causally rewire the chromatin landscape, and how do those changes then propagate to the transcriptome? This gives us a much more mechanistic, multi-layered view of gene regulation.\nKey Experiment for the Field: The experiments in this paper were performed in cell culture. The ultimate challenge and next frontier is to take this technology in vivo. The key experiment would be to transduce a population of tumor cells with a Perturb-seq library, implant them into an immunocompetent mouse model, and allow a tumor to form. Upon excision, performing scRNA-seq on the tumor would reveal which genetic knockouts causally impact a cell\u0026rsquo;s fitness, metastatic potential, and its interaction with the native immune system within the true complexity of the tumor microenvironment.\nReading the Fine Print: Limitations and Lookouts For all its power, the approach isn\u0026rsquo;t without its caveats. First, the model has to infer which cells actually had a successful gene knockout, as CRISPR is not 100% efficient. This introduces a potential source of noise, as the \u0026ldquo;unaffected\u0026rdquo; cells can dampen the measured average effect size for a given perturbation. Second, the biological context is critical. An effect observed in a cell line grown in a dish may not translate directly to a complex tissue in vivo, where extrinsic signals from neighboring cells can buffer or modify the outcome of a perturbation. Finally, while the paper demonstrated simple pairwise interactions, the combinatorial space of genetic interactions is astronomically large. Systematically screening all pairs, triplets, and higher-order combinations remains a monumental challenge, forcing us to rely on assumptions of sparsity—that most factors don\u0026rsquo;t interact—which may not always be true.\n Reference Dixit, Atray, et al. \u0026ldquo;Perturb-Seq: dissecting molecular circuits with scalable single-cell RNA profiling of pooled genetic screens.\u0026quot; cell 167.7 (2016): 1853-1866.\n","date":1612310400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612310400,"objectID":"c37b51e5dbf2626110e70edb07cb6e85","permalink":"https://zqzneptune.github.io/post/2021-02-03_perturbseqinit/","publishdate":"2021-02-03T00:00:00Z","relpermalink":"/post/2021-02-03_perturbseqinit/","section":"post","summary":"Perturb-seq combines pooled CRISPR screens with single-cell transcriptomics to systematically link genetic perturbations to their complex molecular phenotypes at scale.","tags":["Perturb-seq","CRISPR","Causal-Inference","scRNA-seq","Systems-Biology"],"title":"Perturb-Seq: Moving from 'What Is' to 'What If' in a Single Experiment","type":"post"},{"authors":["Qingzhou Zhang"],"categories":["Computational Methods"],"content":"The 30-Second Lowdown I love papers that challenge a core assumption we\u0026rsquo;ve all been working with. In this short but powerful correspondence, Valentine Svensson re-examines the widely held belief that droplet-based single-cell RNA-seq data has \u0026ldquo;too many\u0026rdquo; zeros due to technical failures, a phenomenon often called \u0026ldquo;dropout.\u0026rdquo; Using a series of clever analyses on negative control datasets, he demonstrates that the number of observed zeros is almost perfectly explained by standard statistical models of molecule counting. The punchline? The \u0026ldquo;excess\u0026rdquo; zeros we see in our biological data aren\u0026rsquo;t technical noise to be corrected; they are a reflection of real biology.\nThe Ghost in the Machine: Are Zeros Signal or Noise? A fundamental question in single-cell genomics has always been this: when my data matrix shows a zero for a given gene in a specific cell, what does it mean? Did the technology simply fail to capture an expressed transcript (a \u0026ldquo;technical zero\u0026rdquo;), or is that gene genuinely not being expressed (a \u0026ldquo;biological zero\u0026rdquo;)?\nThis isn\u0026rsquo;t just an academic question—it dictates how we build our models. For years, the field has leaned heavily on the idea that technical zeros are rampant, especially in high-throughput droplet methods. This assumption has spawned an entire cottage industry of computational methods for \u0026ldquo;imputation\u0026rdquo;—algorithms designed to predict and fill in these supposed missing values. But if that foundational assumption is shaky, it means we might be spending our time \u0026ldquo;fixing\u0026rdquo; a problem that doesn\u0026rsquo;t exist, and potentially even corrupting the real biological signal in the process.\nA Clean Experiment to Settle the Score The beauty of this paper lies not in a complex new algorithm, but in its elegant application of statistical first principles to the right kind of data. Svensson leverages public negative control datasets where, instead of single cells, a uniform solution of RNA is encapsulated into droplets. This creates a perfect testbed: a system with zero biological variation, where any deviation from a simple sampling model must be technical.\nHe then fits a standard count model—the negative binomial distribution—to this data. This model is a workhorse for count data and accounts for the fact that capturing molecules is a random process. The result is striking: the model perfectly predicts the observed fraction of zeros without needing any extra \u0026ldquo;zero-inflation\u0026rdquo; component. It’s a textbook case of Occam\u0026rsquo;s razor; the simplest model fits the technical data perfectly.\nThe Finding That Changes Things The \u0026lsquo;aha!\u0026rsquo; moment for me is the stark visual contrast in Figure 1. When you look at the plots from the technical control experiments (panels a-e), the black dots (observed zero fraction) sit right on top of the gray line (the model\u0026rsquo;s prediction). There is no \u0026ldquo;excess\u0026rdquo; zero problem.\nThen, you look at the plots from real biological samples (panels f-h). Here, you see a clear deviation: many genes have more zeros than predicted by a simple model with a single \u0026ldquo;dispersion\u0026rdquo; parameter for all genes. This is the deviation that has fueled the dropout narrative. But the author shows that once you allow each gene to have its own biological variability (a gene-wise dispersion), the model once again explains the data much better. The takeaway is unambiguous: the platform itself isn\u0026rsquo;t systematically failing. The extra zeros come from biological heterogeneity. Some cells express a gene, others don\u0026rsquo;t. That’s biology, not a bug.\nWhy This Matters for Building Predictive Models This paper lands squarely on my intellectual home turf. My entire research program is geared towards building interpretable, predictive models of living tissues, and that starts with respecting the data. For years, we\u0026rsquo;ve seen increasingly complex imputation models, many of which are black boxes that fundamentally alter the raw counts before any biological questions are asked. This work provides strong evidence that this entire preprocessing step might be a misguided effort.\nIf the zeros are real, then trying to \u0026ldquo;fill them in\u0026rdquo; isn\u0026rsquo;t just unnecessary; it\u0026rsquo;s actively destroying information. This gives me much more confidence in using models that work directly with the raw count data, like negative binomial generalized linear models (GLMs). These models are statistically appropriate, more interpretable, and keep us closer to the ground truth of the experiment.\nFor my work in leukemia chemoresistance, this is critical. A gene being truly \u0026ldquo;off\u0026rdquo; in a drug-resistant subclone versus \u0026ldquo;on\u0026rdquo; in a sensitive one is a powerful piece of causal evidence. It\u0026rsquo;s a signal I want to model directly, not a technical error to be smoothed over by an imputation algorithm.\nUntapped Potential and the Road Ahead This work clarifies our thinking, but also points to new directions.\nMy Next Computational Step: The immediate implication is to challenge my own preprocessing pipelines. I plan to systematically benchmark how much imputation actually hurts the ability to identify the effects of genetic perturbations in my Perturb-seq data. My hypothesis, strengthened by this paper, is that for detecting the strong, often binary on/off gene expression changes induced by CRISPR guides, working directly with the counts will be more powerful and robust than working with imputed data. I\u0026rsquo;ll design this benchmark using my existing T-ALL datasets.\nKey Experiment for the Field: The author correctly points out that there\u0026rsquo;s a lack of comparable negative control data for plate-based scRNA-seq methods. To truly settle this debate across technologies, the community needs a gold-standard \u0026ldquo;zero-free\u0026rdquo; control experiment for a popular plate-based method like SMART-seq3. This would allow for a definitive, apples-to-apples comparison of the noise profiles and tell us if those platforms do have unique technical artifacts that might warrant a different statistical approach.\nA Healthy Dose of Skepticism My main critique is that as a \u0026ldquo;correspondence\u0026rdquo; piece, the analysis is necessarily brief. The conclusion—\u0026ldquo;Droplet scRNA-seq is not zero-inflated\u0026rdquo;—is very broad, but the evidence is strongest for UMI-based droplet platforms. The argument against plate-based methods is less direct, relying on re-analysis of a single dataset and another group\u0026rsquo;s simulation study. While the evidence presented for droplet methods is compelling, I\u0026rsquo;d be cautious about over-generalizing this to all scRNA-seq technologies without more direct, controlled comparisons. The core message is a crucial course correction for the field, but the nuanced differences between technologies still matter.\nReference: Droplet scRNA-seq is not zero-inflated Nature Biotechnology (2020), by Valentine Svensson\n","date":1579478400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579478400,"objectID":"7ddf0bb65e177da9b85aceb95b491efa","permalink":"https://zqzneptune.github.io/post/2020-01-20-zerodrop/","publishdate":"2020-01-20T00:00:00Z","relpermalink":"/post/2020-01-20-zerodrop/","section":"post","summary":"This analysis elegantly demonstrates that the high number of zeros in droplet-based scRNA-seq is not a technical artifact but is well-explained by standard count statistics, implying \"excess\" zeros are biological.","tags":["scRNA-seq","Computational-Methods","Statistical-Modeling","Zero-Inflation"],"title":"Busting the Myth of the scRNA-seq \"Dropout\"","type":"post"},{"authors":null,"categories":["Software","Publication"],"content":"The EPIC toolkit was initially published here: Hu, L. Z., et al. \u0026ldquo;EPIC: software toolkit for elution profile-based inference of protein complexes.\u0026rdquo; Nature methods 16.8 (2019): 737-742. Link to the publication\nForked from the orignial repository, I have created RunEPIC to provide the code to run EPIC locally.\n1. Environment The main function in EPIC was implemented in Python, given the headache caused by various libraries, the Anaconda enrionment was used. Simply install Anaconda Python 2.7 version for your convience, and we will start from there.\n2. Prerequisite Let\u0026rsquo;s create the virtual enrionment:\npath to the anaconda directory/bin/conda create -n EPIC python=2.7 anaconda  then we need step up some chanels:\n(EPIC)conda config --add channels defaults (EPIC)conda config --add channels bioconda (EPIC)conda config --add channels conda-forge  get R installed:\n(EPIC)conda install r  start R:\n(EPIC)R  install wccsom for computing WCC scores:\n\u0026gt; install.packages(\u0026quot;kohonen\u0026quot;) \u0026gt; install.packages(\u0026quot;https://cran.r-project.org/src/contrib/Archive/wccsom/wccsom_1.2.11.tar.gz\u0026quot;, type = \u0026quot;source\u0026quot;) \u0026gt; q()  install conda packages:\nconda install requests scikit-learn beautifulsoup4 mock numpy rpy2 python -mpip install -U matplotlib  lastly, make sure Java is installed, so that ClusterOne.jar could be used.\n3. Run EPIC git clone https://github.com/zqzneptune/RunEPIC.git  The main.py in EPIC implemented all the functions:\npython directory to RunEPIC/src/main.py \\ -s 11101001 \\ [Directory to Input Folder/] \\ -c [path to the gold standard file ] \\ [Directory to Output Folder/] \\ -o PrefixName \\ -M RF \\ -n 6 \\ -m COMB \\ -f STRING  ","date":1576195994,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576195994,"objectID":"3eb5b4e7c43222d2c4ba325dcecd7551","permalink":"https://zqzneptune.github.io/post/2019-12-12-runepic/","publishdate":"2019-12-12T18:13:14-06:00","relpermalink":"/post/2019-12-12-runepic/","section":"post","summary":"The EPIC toolkit was initially published here: Hu, L. Z., et al. \u0026ldquo;EPIC: software toolkit for elution profile-based inference of protein complexes.\u0026rdquo; Nature methods 16.8 (2019): 737-742. Link to the publication\nForked from the orignial repository, I have created RunEPIC to provide the code to run EPIC locally.\n1. Environment The main function in EPIC was implemented in Python, given the headache caused by various libraries, the Anaconda enrionment was used.","tags":["Python","Interactome","BF-MS"],"title":"Run EPIC","type":"post"},{"authors":null,"categories":null,"content":"","date":1569024000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569024000,"objectID":"d191d03425e109bcec18ec618f06dd25","permalink":"https://zqzneptune.github.io/publication/j.isci.2019.08.057/","publishdate":"2019-09-04T00:00:00Z","relpermalink":"/publication/j.isci.2019.08.057/","section":"publication","summary":"2019","tags":["Single Cell RNA-seq","Biochemical Fractionation","Mitochondrial","Interactome","Neurogenesis"],"title":"Rewiring of the Human Mitochondrial Interactome during Neuronal Reprogramming Reveals Regulators of the Respirasome and Neurogenesis","type":"publication"},{"authors":null,"categories":null,"content":"","date":1566864000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566864000,"objectID":"19934a68eeaf33edc440413605d0a145","permalink":"https://zqzneptune.github.io/publication/978-981-13-8367-0_6/","publishdate":"2019-08-27T00:00:00Z","relpermalink":"/publication/978-981-13-8367-0_6/","section":"publication","summary":"2018","tags":["Affinity purification","Protein complex","Mass spectrometry","Mitochondrial","Interactome"],"title":"A Tag-Based Affinity Purification Mass Spectrometry Workflow for Systematic Isolation of the Human Mitochondrial Protein Complexes","type":"publication"},{"authors":null,"categories":["Software"],"content":"This R package implements statistical modelling of affinity purification–mass spectrometry (AP-MS) data to compute confidence scores to identify bona fide protein-protein interactions (PPI).\nInstallation The development version can be installed through github:\ndevtools::install_github(repo=\u0026quot;zqzneptune/SMAD\u0026quot;) library(SMAD)  Input Data A demo data.frame was provided as a hint how the input data should strcutured in order to run the scoring functions:\ndata(TestDatInput) colnames(TestDataInput) [1] \u0026quot;idRun\u0026quot; \u0026quot;idBait\u0026quot; \u0026quot;idPrey\u0026quot; \u0026quot;countPrey\u0026quot; \u0026quot;lenPrey\u0026quot;     idRun idBait idPrey countPrey lenPrey     Unique ID of one AP-MS run Bait ID Prey ID Prey peptide count Protein sequence length of the prey    In case of duplcates, a suffix or prefix of e.g. \u0026ldquo;A\u0026rdquo;, \u0026ldquo;B\u0026rdquo; could be added to idRun in order to make \u0026ldquo;idRun-idBait\u0026rdquo; combination unique to each replicate.\nRun scoring 1. CompPASS Comparative Proteomic Analysis Software Suite (CompPASS) is based on spoke model. This algorithm was developed by Dr. Mathew Sowa for defining the human deubiquitinating enzyme interaction landscape (Sowa, Mathew E., et al., 2009). The implementation of this algorithm was inspired by Dr. Sowa\u0026rsquo;s online tutorial. The output includes Z-score, S-score, D-score and WD-score. In its implementation in BioPlex 1.0 (Huttlin, Edward L., et al., 2015) and BioPlex 2.0 (Huttlin, Edward L., et al., 2017), a naive Bayes classifier that learns to distinguish true interacting proteins from non-specific background and false positive identifications was included in the compPASS pipline. This function was optimized from the source code.\nThe input data.frame, datInput, should include:idRun, idBait, idPrey and countPrey.\ndatScore \u0026lt;- CompPASS(datInput)  2. DICE The Dice coefficient is used to score the interaction scores across prey pair-wise combinations, which was proposed by (Bing Zhang et al., 2008)\nThe input data.frame, datInput, should include:idRun and idPrey.\ndatScore \u0026lt;- DICE(datInput)  3. Hart Hart scoring algorithm is based on a hypergeometric distribution error model (Hart et al., 2007).\nThe input data.frame, datInput, should include:idRun and idPrey.\ndatScore \u0026lt;- Hart(datInput)  4. HGScore HGScore algorithm is based on a hypergeometric distribution error model (Hart et al., 2007) with incorporation of NSAF (Zybailov, Boris, et al., 2006). This algorithm was first introduced to predict the protein complex network of Drosophila melanogaster (Guruharsha, K. G., et al., 2011). This scoring algorithm was based on matrix model.\nThe input data.frame, datInput, should include:idRun, idPrey, countPrey and lenPrey.\ndatScore \u0026lt;- HG(datInput)  5. PE PE incorporated both spoke and matrix model as repored in (Sean R. Collins, et al., 2007).\nThe input data.frame, datInput, should include:idRun, idBait and idPrey.\ndatScore \u0026lt;- PE(datInput)  License MIT @ Qingzhou Zhang\n","date":1558537994,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558537994,"objectID":"7288a74d1fd5f425fb7d0f945a123196","permalink":"https://zqzneptune.github.io/post/2019-05-22-smad/","publishdate":"2019-05-22T09:13:14-06:00","relpermalink":"/post/2019-05-22-smad/","section":"post","summary":"This R package implements statistical modelling of affinity purification–mass spectrometry (AP-MS) data to compute confidence scores to identify bona fide protein-protein interactions (PPI).\nInstallation The development version can be installed through github:\ndevtools::install_github(repo=\u0026quot;zqzneptune/SMAD\u0026quot;) library(SMAD)  Input Data A demo data.frame was provided as a hint how the input data should strcutured in order to run the scoring functions:\ndata(TestDatInput) colnames(TestDataInput) [1] \u0026quot;idRun\u0026quot; \u0026quot;idBait\u0026quot; \u0026quot;idPrey\u0026quot; \u0026quot;countPrey\u0026quot; \u0026quot;lenPrey\u0026quot;     idRun idBait idPrey countPrey lenPrey     Unique ID of one AP-MS run Bait ID Prey ID Prey peptide count Protein sequence length of the prey    In case of duplcates, a suffix or prefix of e.","tags":["R","Proteomics","Interactome","AP-MS"],"title":"Statistical Modelling of AP-MS Data (SMAD)","type":"post"},{"authors":null,"categories":["Awsome"],"content":"A collection of resources regarding affinity purification mass spectrometry proteomics for the identification of protein-protein interactions.\nAlgorithms    Year Algorithm Publication Implementation     2006 SAI (socio-affinity index) Anne-Claude Gavin et al., Nature    2007 partial least squares based regression model Rob M Ewing et al., Mol Syst Biol    2007 PE (purification enrichment) Sean R. Collins et al., Molecular \u0026amp; Cellular Proteomics SMAD   2007 Hart G Traver Hart et al., BMC Bioinformatics SMAD   2008 Dice coefficient Bing Zhang et al., Bioinformatics SMAD   2008 PP-NSAF Mihaela E. Sardiu et al., PNAS    2009 CompPASS Mathew E.Sowa et al., Cell SMAD   2010 Decontaminator MathieLavallée-Adam et al. J. Proteome Res.     2011 MiST Stefanie Jäger et al., Nature mist   2011 HGScore K.G.Guruharsha et al., Cell SMAD   2011 SAINT Hyungwon Choi et al., Nature Methods SAINT   2015 SFINX Kevin Titeca et al. J. Proteome Res. SFINX    Datasets    Year Species Abstract Publication     2002 S.cerevisiae 725 bait proteins, one-step immuno-affinity purification based on the Flag epitope tag Yuen Ho et al., Nature   2002 S.cerevisiae tandem-affinity purification processed 1,739 genes Anne-Claude Gavin et al., Nature   2006 S.cerevisiae Genome-wide TAP–MS, first introduced Anne-Claude Gavin et al., Nature   2009 H.sapiens Human Deubiquitinating Enzyme Interaction Landscape(DUB) Mathew E.Sowa et al., Cell   2010 S.cerevisiae kinase and phosphatase interaction (KPI) network Ashton Breitkreutz et al., Science   2009 H.sapiens autophagy interaction network (AIN) Christian Behrends et al., Nature   2011 D.melanogaster a Drosophila protein interaction map (DPiM) K.G.Guruharsha et al., Cell   2012 S.cerevisiae membrane-protein complexes in yeast Mohan Babu et al., Nature   2014 H.sapiens A comprehensive chromatin-related protein-protein interaction map Edyta Marcon et al., Cell Reports   2015 H.sapiens BioPlex v1 Edward L. Huttlin et al., Cell   2015 H.sapiens Autism Spectrum Disorders related Jingjing Li et al., Cell Systems   2016 H.sapiens PPI mapping of 50 unannotated mitochondrial proteins Brendan J.Floyd et al., Molecular Cell   2016 H.sapiens Comprehensive mitochondrial sirtuin interactome Wen Yang et al., Cell   2017 H.sapiens BioPlex v2 Edward L. Huttlin et al., Cell   2017 E.coli Global landscape of cell envelope protein complexes Mohan Babu et al., Nature Biotech   2017 H.sapiens A Map of Human Mitochondrial Protein Interactions related to Neurodegeneration Ramy H.Malty et al., Cell Systems    ","date":1531063394,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531063394,"objectID":"9437dbc4b77c086996be518e755ea4a3","permalink":"https://zqzneptune.github.io/post/2018-07-08-apms/","publishdate":"2018-07-08T09:23:14-06:00","relpermalink":"/post/2018-07-08-apms/","section":"post","summary":"A collection of resources regarding affinity purification mass spectrometry proteomics for the identification of protein-protein interactions.\nAlgorithms    Year Algorithm Publication Implementation     2006 SAI (socio-affinity index) Anne-Claude Gavin et al., Nature    2007 partial least squares based regression model Rob M Ewing et al., Mol Syst Biol    2007 PE (purification enrichment) Sean R. Collins et al., Molecular \u0026amp; Cellular Proteomics SMAD   2007 Hart G Traver Hart et al.","tags":["AP-MS","Interactome"],"title":"Awsome affinity purification mass spectrometry (AP-MS)","type":"post"},{"authors":null,"categories":null,"content":"","date":1511740800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1511740800,"objectID":"b08780d0d7efa313f23283a4f8efba74","permalink":"https://zqzneptune.github.io/publication/nbt.4024/","publishdate":"2017-11-27T00:00:00Z","relpermalink":"/publication/nbt.4024/","section":"publication","summary":"2017","tags":["AP-MS","E.coli","Interactome","Landscape"],"title":"Global landscape of cell envelope protein complexes in Escherichia coli","type":"publication"},{"authors":null,"categories":null,"content":"","date":1510876800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1510876800,"objectID":"fce5f6f4ccb031c1dd5a51a68cafc9c5","permalink":"https://zqzneptune.github.io/publication/j.cels.2017.10.010/","publishdate":"2017-11-08T00:00:00Z","relpermalink":"/publication/j.cels.2017.10.010/","section":"publication","summary":"2017","tags":["AP-MS","Mitochondrial","Interactome","Neurodegeneration"],"title":"A Map of Human Mitochondrial Protein Interactions Linked to Neurodegeneration Reveals New Mechanisms of Redox Homeostasis and NF-κB Signaling","type":"publication"},{"authors":null,"categories":null,"content":"","date":1505952000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505952000,"objectID":"6aa1d9e09ed86cdcf2c7437194c129fc","permalink":"https://zqzneptune.github.io/publication/oncotarget.22413/","publishdate":"2017-09-21T00:00:00Z","relpermalink":"/publication/oncotarget.22413/","section":"publication","summary":"2017","tags":["Whole Exome Sequencing","Mitochondrial","Interactome","Renal Oncocytoma"],"title":"Renal oncocytoma characterized by the defective complex I of the respiratory chain boosts the synthesis of the ROS scavenger glutathione","type":"publication"},{"authors":null,"categories":null,"content":"","date":1412640000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1412640000,"objectID":"c0a8cbb408ad43c03def7c0e376932f7","permalink":"https://zqzneptune.github.io/publication/rged/","publishdate":"2014-09-24T00:00:00Z","relpermalink":"/publication/rged/","section":"publication","summary":"2014","tags":["Database","Gene Expression"],"title":"Renal Gene Expression Database (RGED) a relational database of gene expression profiles in kidney disease","type":"publication"},{"authors":null,"categories":["Database","Publication"],"content":"The Renal Gene Expression Database (RGED) is online. Number of samples colleceted in the database reached around ~10,000, including DNA microarray and RNA-seq experiments.\nJust go ahead to this URL: http://rged.wall-eva.net/\n","date":1406049194,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1406049194,"objectID":"a7313c4b7d36d710550bcf974cf8d75c","permalink":"https://zqzneptune.github.io/post/2014-09-23-rged/","publishdate":"2014-07-23T01:13:14+08:00","relpermalink":"/post/2014-09-23-rged/","section":"post","summary":"The Renal Gene Expression Database (RGED) is online. Number of samples colleceted in the database reached around ~10,000, including DNA microarray and RNA-seq experiments.\nJust go ahead to this URL: http://rged.wall-eva.net/","tags":["Renal Disease","R","Gene Expresssion","PHP"],"title":"Hello, RGED!","type":"post"}]